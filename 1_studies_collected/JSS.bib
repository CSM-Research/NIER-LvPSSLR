@article{GAROUSI2020110570,
title = {Software-testing education: A systematic literature mapping},
journal = {Journal of Systems and Software},
volume = {165},
pages = {110570},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110570},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220300510},
author = {Vahid Garousi and Austen Rainer and Per Lauvås and Andrea Arcuri},
keywords = {Software testing, Software-testing education, Software-engineering education, Education research, Systematic literature review, Systematic literature mapping},
abstract = {Context
With the rising complexity and scale of software systems, there is an ever-increasing demand for sophisticated and cost-effective software testing. To meet such a demand, there is a need for a highly-skilled software testing work-force (test engineers) in the industry. To address that need, many university educators worldwide have included software-testing education in their software engineering (SE) or computer science (CS) programs. Many papers have been published in the last three decades (as early as 1992) to share experience from such undertakings.
Objective
Our objective in this paper is to summarize the body of experience and knowledge in the area of software-testing education to benefit the readers (both educators and researchers) in designing and delivering software testing courses in university settings, and to also conduct further education research in this area.
Method
To address the above need, we conducted a systematic literature mapping (SLM) to synthesize what the community of educators have published on this topic. After compiling a candidate pool of 307 papers, and applying a set of inclusion/exclusion criteria, our final pool included 204 papers published between 1992 and 2019.
Results
The topic of software-testing education is becoming more active, as we can see by the increasing number of papers. Many pedagogical approaches (how to best teach testing), course-ware, and specific tools for testing education have been proposed. Many challenges in testing education and insights on how to overcome those challenges have been proposed.
Conclusion
This paper provides educators and researchers with a classification of existing studies within software-testing education. We further synthesize challenges and insights reported when teaching software testing. The paper also provides a reference (“index”) to the vast body of knowledge and experience on teaching software testing. Our mapping study aims to help educators and researchers to identify the best practices in this area to effectively plan and deliver their software testing courses, or to conduct further education-research in this important area.}
}
@article{PACHECO20122171,
title = {A systematic literature review of stakeholder identification methods in requirements elicitation},
journal = {Journal of Systems and Software},
volume = {85},
number = {9},
pages = {2171-2181},
year = {2012},
note = {Selected papers from the 2011 Joint Working IEEE/IFIP Conference on Software Architecture (WICSA 2011)},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2012.04.075},
url = {https://www.sciencedirect.com/science/article/pii/S0164121212001288},
author = {Carla Pacheco and Ivan Garcia},
keywords = {Systematic review, Requirements engineering, Stakeholder identification, Requirements elicitation, Software engineering},
abstract = {This paper presents a systematic review of relevant published studies related to topics in Requirements Engineering, specifically, concerning stakeholder identification methods in requirements elicitation, dated from 1984 to 2011. Addressing four specific research questions, this systematic literature review shows the following evidence gathered from these studies: current status of stakeholder identification in software requirement elicitation, the best practices recommended for its performance, consequences of incorrect identification in requirements quality, and, aspects which need to be improved. Our findings suggest that the analyzed approaches still have serious limitations in terms of covering all aspects of stakeholder identification as an important part of requirements elicitation. However, through correctly identifying and understanding the stakeholders, it is possible to develop high quality software.}
}
@article{RAZIAN2022111290,
title = {Service composition in dynamic environments: A systematic review and future directions},
journal = {Journal of Systems and Software},
volume = {188},
pages = {111290},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111290},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222000474},
author = {Mohammadreza Razian and Mohammad Fathian and Rami Bahsoon and Adel N. Toosi and Rajkumar Buyya},
keywords = {Service composition, Uncertainty, Cloud computing, Distributed services},
abstract = {Distributed computing paradigms such as cloud, mobile, Internet of Things, and Fog have enabled new modalities for building enterprise architectures through service composition. The fundamental premise is that the application can benefit from functionally equivalent services that can be traded in the cloud or services repositories. These services can vary in their Quality of Services (QoS) and cost provision. Accordingly, the problem of service composition is the process of choosing a configuration of candidate services from a pool of available ones, considering QoS attribute, cost, and users’ preference. Due to the inherent dynamism in service computing environments and communication networks, the advertised QoS values might fluctuate; therefore, service composition under uncertainty is inevitable and challenges satisfying Services Level Agreement (SLA). In this paper, we present a systematic literature review to investigate and classify the existing studies in service composition under uncertainty. We identified 100 relevant studies published between the year 2007 and 2020. To the best of our knowledge, this work is the first to explicate a focused systematic review, classification, taxonomy of approaches, and trends along with their assumptions and applications; and to discuss future research directions in service composition under uncertainty.}
}
@article{MYLLYAHO2021111050,
title = {Systematic literature review of validation methods for AI systems},
journal = {Journal of Systems and Software},
volume = {181},
pages = {111050},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111050},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221001473},
author = {Lalli Myllyaho and Mikko Raatikainen and Tomi Männistö and Tommi Mikkonen and Jukka K. Nurminen},
keywords = {Artificial intelligence, Machine learning, Validation, Testing, V&V, Systematic literature review},
abstract = {Context:
Artificial intelligence (AI) has made its way into everyday activities, particularly through new techniques such as machine learning (ML). These techniques are implementable with little domain knowledge. This, combined with the difficulty of testing AI systems with traditional methods, has made system trustworthiness a pressing issue.
Objective:
This paper studies the methods used to validate practical AI systems reported in the literature. Our goal is to classify and describe the methods that are used in realistic settings to ensure the dependability of AI systems.
Method:
A systematic literature review resulted in 90 papers. Systems presented in the papers were analysed based on their domain, task, complexity, and applied validation methods.
Results:
The validation methods were synthesized into a taxonomy consisting of trial, simulation, model-centred validation, and expert opinion. Failure monitors, safety channels, redundancy, voting, and input and output restrictions are methods used to continuously validate the systems after deployment.
Conclusions:
Our results clarify existing strategies applied to validation. They form a basis for the synthesization, assessment, and refinement of AI system validation in research and guidelines for validating individual systems in practice. While various validation strategies have all been relatively widely applied, only few studies report on continuous validation.}
}
@article{RASHID2015150,
title = {Toward the tools selection in model based system engineering for embedded systems—A systematic literature review},
journal = {Journal of Systems and Software},
volume = {106},
pages = {150-163},
year = {2015},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2015.04.089},
url = {https://www.sciencedirect.com/science/article/pii/S016412121500103X},
author = {Muhammad Rashid and Muhammad Waseem Anwar and Aamir M. Khan},
keywords = {MBSE, Embedded systems, Tools},
abstract = {Model based system engineering (MBSE) is a systematic approach of modeling which is frequently used to support requirement specification, design, verification and validation activities of system development. However, it is difficult to customize MBSE approach for the development of embedded systems due to their diverse behavioral aspects. Furthermore, appropriate tools selection to perform particular MBSE activities is always challenging. This paper focuses on the identification and classification of recent research practices pertaining to embedded systems development through MBSE approach. Consequently, a comprehensive analysis of various MBSE tools has been presented. Systematic literature review (SLR) has been used to identify 61 research practices published during 2008–2014. The identified researches have been classified into six different categories to analyze various aspects of MBSE approach for embedded systems. Consequently, 39 preliminary tools are identified that have been used in recent researches. Furthermore, classification and evaluation of tools have been presented. This research highlights important trends and approaches of MBSE to support development of embedded systems. A comprehensive investigation of tools in this article facilitates researchers, practitioners and developers to select appropriate tools according to their requirements.}
}
@article{VACCA2021110891,
title = {A systematic literature review of blockchain and smart contract development: Techniques, tools, and open challenges},
journal = {Journal of Systems and Software},
volume = {174},
pages = {110891},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110891},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220302818},
author = {Anna Vacca and Andrea {Di Sorbo} and Corrado A. Visaggio and Gerardo Canfora},
keywords = {Software engineering for blockchain technologies, Software quality, Software metrics, Empirical study, Ethereum, Smart contract},
abstract = {Blockchain platforms and languages for writing smart contracts are becoming increasingly popular. However, smart contracts and blockchain applications are developed through non-standard software life-cycles, in which, for instance, delivered applications can hardly be updated or bugs resolved by releasing a new version of the software. Therefore, this systematic literature review oriented to software engineering aims at highlighting current problems and possible solutions concerning smart contracts and blockchain applications development. In this paper, we analyze 96 articles (written from 2016 to 2020) presenting solutions to tackle software engineering-specific challenges related to the development, test, and security assessment of blockchain-oriented software. In particular, we review papers (that appeared in international journals and conferences) relating to six specific topics: smart contract testing, smart contract code analysis, smart contract metrics, smart contract security, Dapp performance, and blockchain applications. Beyond the systematic review of the techniques, tools, and approaches that have been proposed in the literature to address the issues posed by the development of blockchain-based software, for each of the six aforementioned topics, we identify open challenges that require further research.}
}
@article{KARABEYAKSAKALLI2021111014,
title = {Deployment and communication patterns in microservice architectures: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {180},
pages = {111014},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111014},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221001114},
author = {Işıl {Karabey Aksakalli} and Turgay Çelik and Ahmet Burak Can and Bedir Teki̇nerdoğan},
keywords = {Microservice architectures, Microservice deployment, Communication patterns of microservices, Deployment challenges, Communication concerns, Research directions},
abstract = {Context:
Microservice is an architectural style that separates large systems into small functional units to provide better modularity. A key challenge of microservice architecture design frequently discussed in the literature is the identification and decomposition of the service modules. Besides this, two other key challenges can be identified, including the deployment of the modules on the corresponding execution platform, and adopted communication patterns.
Objective:
This study aims to identify and describe the reported deployment approaches, and the communication platforms for microservices in the current literature. Furthermore, we aim to describe the identified obstacles of these approaches as well as the corresponding research directions.
Method:
A systematic literature review (SLR) is conducted using a multiphase study selection process in which we reviewed a total of 239 papers. Among these, we selected 38 of them as primary studies related to the described research questions.
Results:
Based on our study, we could identify three types of deployment approaches and seven different communication patterns. Moreover, we have identified eight challenges related to the deployment and six challenges related to the communication concerns.
Conclusion:
Our study shows that in addition to the identification of modules, the deployment and communication approaches are equally crucial for a successful application of the microservice architecture style. Various deployment approaches and communication patterns appear to be useful for different contexts. The identified research directions in the literature study show that still more research is needed to cope with the current challenges.}
}
@article{CAMPANELLI201585,
title = {Agile methods tailoring – A systematic literature review},
journal = {Journal of Systems and Software},
volume = {110},
pages = {85-100},
year = {2015},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2015.08.035},
url = {https://www.sciencedirect.com/science/article/pii/S0164121215001843},
author = {Amadeu Silveira Campanelli and Fernando Silva Parreiras},
keywords = {Agile method tailoring, Agile practice selection, Software method tailoring},
abstract = {Background: The software development industry has been adopting agile methods instead of traditional software development methods because they are more flexible and can bring benefits such as handling requirements changes, productivity gains and business alignment. Objective: This study seeks to evaluate, synthesize, and present aspects of research on agile methods tailoring including the method tailoring approaches adopted and the criteria used for agile practice selection. Method: The method adopted was a Systematic Literature Review (SLR) on studies published from 2002 to 2014. Results: 56 out of 783 papers have been identified as describing agile method tailoring approaches. These studies have been identified as case studies regarding the empirical research, as solution proposals regarding the research type, and as evaluation studies regarding the research validation type. Most of the papers used method engineering to implement tailoring and were not specific to any agile method on their scope. Conclusion: Most of agile methods tailoring research papers proposed or improved a technique, were implemented as case studies analyzing one case in details and validated their findings using evaluation. Method engineering was the base for tailoring, the approaches are independent of agile method and the main criteria used are internal environment and objectives variables.}
}
@article{LENBERG201515,
title = {Behavioral software engineering: A definition and systematic literature review},
journal = {Journal of Systems and Software},
volume = {107},
pages = {15-37},
year = {2015},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2015.04.084},
url = {https://www.sciencedirect.com/science/article/pii/S0164121215000989},
author = {Per Lenberg and Robert Feldt and Lars Göran Wallgren},
keywords = {Software engineering, Human aspects, Psychology},
abstract = {Throughout the history of software engineering, the human aspects have repeatedly been recognized as important. Even though research that investigates them has been growing in the past decade, these aspects should be more generally considered. The main objective of this study is to clarify the research area concerned with human aspects of software engineering and to create a common platform for future research. In order to meet the objective, we propose a definition of the research area behavioral software engineering (BSE) and present results from a systematic literature review based on the definition. The result indicates that there are knowledge gaps in the research area of behavioral software engineering and that earlier research has been focused on a few concepts, which have been applied to a limited number of software engineering areas. The individual studies have typically had a narrow perspective focusing on few concepts from a single unit of analysis. Further, the research has rarely been conducted in collaboration by researchers from both software engineering and social science. Altogether, this review can help put a broader set of human aspects higher on the agenda for future software engineering research and practice.}
}
@article{PIZZOLETO2019110388,
title = {A systematic literature review of techniques and metrics to reduce the cost of mutation testing},
journal = {Journal of Systems and Software},
volume = {157},
pages = {110388},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.07.100},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219301554},
author = {Alessandro Viola Pizzoleto and Fabiano Cutigi Ferrari and Jeff Offutt and Leo Fernandes and Márcio Ribeiro},
keywords = {Mutation analysis, Mutation testing, Cost reduction, Systematic review},
abstract = {Historically, researchers have proposed and applied many techniques to reduce the cost of mutation testing. It has become difficult to find all techniques and to understand the cost-benefit tradeoffs among them, which is critical to transitioning this technology to practice. This paper extends a prior workshop paper to summarize and analyze the current knowledge about reducing the cost of mutation testing through a systematic literature review. We selected 175 peer-reviewed studies, from which 153 present either original or updated contributions. Our analysis resulted in six main goals for cost reduction and 21 techniques. In the last decade, a growing number of studies explored techniques such as selective mutation, evolutionary algorithms, control-flow analysis, and higher-order mutation. Furthermore, we characterized 18 metrics, with particular interest in the number of mutants to be executed, test cases required, equivalent mutants generated and detected, and mutant execution speedup. We found that cost reduction for mutation is increasingly becoming interdisciplinary, often combining multiple techniques. Additionally, measurements vary even for studies that use the same techniques. Researchers can use our results to find more detailed information about particular techniques, and to design comparable and reproducible experiments.}
}
@article{GIORDANO2022111475,
title = {On the use of artificial intelligence to deal with privacy in IoT systems: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {193},
pages = {111475},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111475},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222001613},
author = {Giammaria Giordano and Fabio Palomba and Filomena Ferrucci},
keywords = {Data privacy, Artificial intelligence, Internet-of-Things, Software engineering for IoT},
abstract = {The Internet of Things (IoT) refers to a network of Internet-enabled devices that can make different operations, like sensing, communicating, and reacting to changes arising in the surrounding environment. Nowadays, the number of IoT devices is already higher than the world population. These devices operate by exchanging data between them, sometimes through an intermediate cloud infrastructure, and may be used to enable a wide variety of novel services that can potentially improve the quality of life of billions of people. Nonetheless, all that glitters is not gold: the increasing adoption of IoT comes with several privacy concerns due to the lack or loss of control over the sensitive data exchanged by these devices. This represents a key challenge for software engineering researchers attempting to address those privacy concerns by proposing (semi-)automated solutions to identify sources of privacy leaks. In this respect, a notable trend is represented by the adoption of smart solutions, that is, the definition of techniques based on artificial intelligence (AI) algorithms. This paper proposes a systematic literature review of the research in smart detection of privacy concerns in IoT devices. Following well-established guidelines, we identify 152 primary studies that we analyze under three main perspectives: (1) What are the privacy concerns addressed with AI-enabled techniques; (2) What are the algorithms employed and how they have been configured/validated; and (3) Which are the domains targeted by these techniques. The key results of the study identified six main tasks targeted through the use of artificial intelligence, like Malware Detection or Network Analysis. Support Vector Machine is the technique most frequently used in literature, however in many cases researchers do not explicitly indicate the domain where to use artificial intelligence algorithms. We conclude the paper by distilling several lessons learned and implications for software engineering researchers.}
}
@article{EDISON20131390,
title = {Towards innovation measurement in the software industry},
journal = {Journal of Systems and Software},
volume = {86},
number = {5},
pages = {1390-1407},
year = {2013},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2013.01.013},
url = {https://www.sciencedirect.com/science/article/pii/S0164121213000058},
author = {Henry Edison and Nauman {bin Ali} and Richard Torkar},
keywords = {Innovation, Measurement, Systematic literature review, Metrics, Empirical study},
abstract = {In today's highly competitive business environments with shortened product and technology life cycle, it is critical for software industry to continuously innovate. This goal can be achieved by developing a better understanding and control of the activities and determinants of innovation. Innovation measurement initiatives assess innovation capability, output and performance to help develop such an understanding. This study explores various aspects relevant to innovation measurement ranging from definitions, measurement frameworks and metrics that have been proposed in literature and used in practice. A systematic literature review followed by an online questionnaire and interviews with practitioners and academics were employed to identify a comprehensive definition of innovation that can be used in software industry. The metrics for the evaluation of determinants, inputs, outputs and performance were also aggregated and categorised. Based on these findings, a conceptual model of the key measurable elements of innovation was constructed from the findings of the systematic review. The model was further refined after feedback from academia and industry through interviews.}
}
@article{MUNAPPY2022111359,
title = {Data management for production quality deep learning models: Challenges and solutions},
journal = {Journal of Systems and Software},
volume = {191},
pages = {111359},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111359},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222000905},
author = {Aiswarya Raj Munappy and Jan Bosch and Helena Holmström Olsson and Anders Arpteg and Björn Brinne},
keywords = {Deep learning, Data management, Production quality DL models, Challenges, Solutions, Validation},
abstract = {Deep learning (DL) based software systems are difficult to develop and maintain in industrial settings due to several challenges. Data management is one of the most prominent challenges which complicates DL in industrial deployments. DL models are data-hungry and require high-quality data. Therefore, the volume, variety, velocity, and quality of data cannot be compromised. This study aims to explore the data management challenges encountered by practitioners developing systems with DL components, identify the potential solutions from the literature and validate the solutions through a multiple case study. We identified 20 data management challenges experienced by DL practitioners through a multiple interpretive case study. Further, we identified 48 articles through a systematic literature review that discuss the solutions for the data management challenges. With the second round of multiple case study, we show that many of these solutions have limitations and are not used in practice due to a combination of four factors: high cost, lack of skill-set and infrastructure, inability to solve the problem completely, and incompatibility with certain DL use cases. Thus, data management for data-intensive DL models in production is complicated. Although the DL technology has achieved very promising results, there is still a significant need for further research in the field of data management to build high-quality datasets and streams that can be used for building production-ready DL systems. Furthermore, we have classified the data management challenges into four categories based on the availability of the solutions.}
}
@article{LACERDA2020110610,
title = {Code smells and refactoring: A tertiary systematic review of challenges and observations},
journal = {Journal of Systems and Software},
volume = {167},
pages = {110610},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110610},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220300881},
author = {Guilherme Lacerda and Fabio Petrillo and Marcelo Pimenta and Yann Gaël Guéhéneuc},
keywords = {Code smells, Refactoring, Tertiary systematic review},
abstract = {Refactoring and smells have been well researched by the software-engineering research community these past decades. Several secondary studies have been published on code smells, discussing their implications on software quality, their impact on maintenance and evolution, and existing tools for their detection. Other secondary studies addressed refactoring, discussing refactoring techniques, opportunities for refactoring, impact on quality, and tools support. In this paper, we present a tertiary systematic literature review of previous surveys, secondary systematic literature reviews, and systematic mappings. We identify the main observations (what we know) and challenges (what we do not know) on code smells and refactoring. We perform this tertiary review using eight scientific databases, based on a set of five research questions, identifying 40 secondary studies between 1992 and 2018. We organize the main observations and challenges about code smell and their refactoring into: smells definitions, most common code-smell detection approaches, code-smell detection tools, most common refactoring, and refactoring tools. We show that code smells and refactoring have a strong relationship with quality attributes, i.e., with understandability, maintainability, testability, complexity, functionality, and reusability. We argue that code smells and refactoring could be considered as the two faces of a same coin. Besides, we identify how refactoring affects quality attributes, more than code smells. We also discuss the implications of this work for practitioners, researchers, and instructors. We identify 13 open issues that could guide future research work. Thus, we want to highlight the gap between code smells and refactoring in the current state of software-engineering research. We wish that this work could help the software-engineering research community in collaborating on future work on code smells and refactoring.}
}
@article{KHAN2011686,
title = {Factors influencing clients in the selection of offshore software outsourcing vendors: An exploratory study using a systematic literature review},
journal = {Journal of Systems and Software},
volume = {84},
number = {4},
pages = {686-699},
year = {2011},
note = {The Ninth International Conference on Quality Software},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2010.12.010},
url = {https://www.sciencedirect.com/science/article/pii/S0164121210003298},
author = {Siffat Ullah Khan and Mahmood Niazi and Rashid Ahmad},
keywords = {Offshore software development outsourcing (OSDO), Vendors, Systematic literature review, SOVRM},
abstract = {Context
Offshore software development outsourcing is a modern business strategy for developing high quality software at low cost.
Objective
The objective of this research paper is to identify and analyse factors that are important in terms of the competitiveness of vendor organisations in attracting outsourcing projects.
Method
We performed a systematic literature review (SLR) by applying our customised search strings which were derived from our research questions. We performed all the SLR steps, such as the protocol development, initial selection, final selection, quality assessment, data extraction and data synthesis.
Results
We have identified factors such as cost-saving, skilled human resource, appropriate infrastructure, quality of product and services, efficient outsourcing relationships management, and an organisation's track record of successful projects which are generally considered important by the outsourcing clients. Our results indicate that appropriate infrastructure, cost-saving, and skilled human resource are common in three continents, namely Asia, North America and Europe. We identified appropriate infrastructure, cost-saving, and quality of products and services as being common in three types of organisations (small, medium and large). We have also identified four factors-appropriate infrastructure, cost-saving, quality of products and services, and skilled human resource as being common in the two decades (1990–1999 and 2000–mid 2008).
Conclusions
Cost-saving should not be considered as the driving factor in the selection process of software development outsourcing vendors. Vendors should rather address other factors in order to compete in the OSDO business, such as skilled human resource, appropriate infrastructure and quality of products and services.}
}
@article{PEREZ2020110657,
title = {Systematic literature reviews in software engineering—enhancement of the study selection process using Cohen’s Kappa statistic},
journal = {Journal of Systems and Software},
volume = {168},
pages = {110657},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110657},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220301217},
author = {Jorge Pérez and Jessica Díaz and Javier Garcia-Martin and Bernardo Tabuenca},
keywords = {Systematic review, Evidence-based practice, Cohen’s kappa},
abstract = {Context:
Systematic literature reviews (SLRs) rely on a rigorous and auditable methodology for minimizing biases and ensuring reliability. A common kind of bias arises when selecting studies using a set of inclusion/exclusion criteria. This bias can be decreased through dual revision, which makes the selection process more time-consuming and remains prone to generating bias depending on how each researcher interprets the inclusion/exclusion criteria.
Objective:
To reduce the bias and time spent in the study selection process, this paper presents a process for selecting studies based on the use of Cohen’s Kappa statistic. We have defined an iterative process based on the use of this statistic during which the criteria are refined until obtain almost perfect agreement (k>0.8). At this point, the two researchers interpret the selection criteria in the same way, and thus, the bias is reduced. Starting from this agreement, dual review can be eliminated; consequently, the time spent is drastically shortened.
Method:
The feasibility of this iterative process for selecting studies is demonstrated through a tertiary study in the area of software engineering on works that were published from 2005 to 2018.
Results:
The time saved in the study selection process was 28% (for 152 studies) and if the number of studies is sufficiently large, the time saved tend asymptotically to 50%.
Conclusions:
Researchers and students may take advantage of this iterative process for selecting studies when conducting SLRs to reduce bias in the interpretation of inclusion and exclusion criteria. It is especially useful for research with few resources.}
}
@article{LEWIS2015158,
title = {Architectural tactics for cyber-foraging: Results of a systematic literature review},
journal = {Journal of Systems and Software},
volume = {107},
pages = {158-186},
year = {2015},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2015.06.005},
url = {https://www.sciencedirect.com/science/article/pii/S0164121215001211},
author = {Grace Lewis and Patricia Lago},
keywords = {Mobile cloud computing, Cyber-foraging, Software architecture},
abstract = {Mobile devices have become for many the preferred way of interacting with the Internet, social media and the enterprise. However, mobile devices still do not have the computing power and battery life that will allow them to perform effectively over long periods of time, or for executing applications that require extensive communication, computation, or low latency. Cyber-foraging is a technique to enable mobile devices to extend their computing power and storage by offloading computation or data to more powerful servers located in the cloud or in single-hop proximity. This article presents the results of a systematic literature review (SLR) on architectures that support cyber-foraging. Elements of the identified architectures were codified in the form of Architectural Tactics for Cyber-Foraging. These tactics will help architects extend their design reasoning toward cyber-foraging as a way to support the mobile applications of the present and the future.}
}
@article{ALDAVE2019110396,
title = {Leveraging creativity in requirements elicitation within agile software development: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {157},
pages = {110396},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.110396},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219301712},
author = {Ainhoa Aldave and Juan M. Vara and David Granada and Esperanza Marcos},
keywords = {Software development, Software project management, Agile methodologies, Requirements elicitation, Creative thinking, Systematic review},
abstract = {Agile approaches tend to focus solely on scoping and simplicity rather than on problem solving and discovery. This hampers the development of innovative solutions. Additionally, little has been said about how to capture and represent the real user needs. To fill this gap, some authors argue in favor of the application of “Creative thinking” for requirements elicitation within agile software development. This synergy between creativeness and agility has arisen as a new means of bringing innovation and flexibility to increasingly demanding software. The aim of the present study is therefore to employ a systematic review to investigate the state-of-the-art of those approaches that leverage creativity in requirements elicitation within Agile Software Development, as well as the benefits, limitations and strength of evidence of these approaches. The review was carried out by following the guidelines proposed by Dr. Kitchenham. The search strategy identified 1451 studies, 17 of which were eventually classified as primary studies. The selected studies contained 13 different and unique proposals. These approaches provide evidence that enhanced creativity in requirements elicitation can be successfully implemented in real software projects. We specifically observed that projects related to user interface development, such as those for mobile or web applications, are good candidates for the use of these approaches. We have also found that agile methodologies such as Scrum, Extreme Programming or methodologies based on rapid modelling are preferred when introducing creativity into requirements elicitation. Despite this being a new research field, there is a mixture of techniques, tools and processes that have already been and are currently being successfully tested in industry. Finally, we have found that, although creativity is an important ingredient with which to bring about innovation, it is not always sufficient to generate new requirements because this needs to be followed by user engagement and a specific context in which proper conditions, such as flexibility, time or resources, have to be met.}
}
@article{GHAPANCHI2011238,
title = {Antecedents to IT personnel's intentions to leave: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {84},
number = {2},
pages = {238-249},
year = {2011},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2010.09.022},
url = {https://www.sciencedirect.com/science/article/pii/S0164121210002645},
author = {Amir Hossein Ghapanchi and Aybuke Aurum},
keywords = {IT personnel, Intention to leave, Employee retention, Employee turnover, Systematic review},
abstract = {This paper undertakes a systematic review to gain insight into existing studies on the turnover of information technology (IT) personnel. Our systematic review of 72 studies from 1980 to 2008 examines the background and trend of research into IT personnel's intentions to leave their workplaces, in addition to providing a taxonomy of the determinants of their intentions to quit as captured in IT literature. We note a huge growth in the number of academic papers on the topic since 1998. Moreover, most of the research on IT turnover has been undertaken in North America, followed by Asia. Based on the 72 extracted studies, we found a total of 70 conceptually distinct IT turnover drivers. We classified them into the 5 broad categories of individual, organisational, job-related, psychological, and environmental, each containing three to four sub-categories. Finally, this paper presents insightful recommendations for IT practitioners as well as for the research community.}
}
@article{WEBER2021110946,
title = {Brain and autonomic nervous system activity measurement in software engineering: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {178},
pages = {110946},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.110946},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221000431},
author = {Barbara Weber and Thomas Fischer and René Riedl},
keywords = {Brain and autonomic nervous system activity measurements, Software engineering, Systematic literature review, Electroencephalography (EEG), Functional magnetic resonance imaging (fMRI), Heart- and skin-related measurements},
abstract = {In the past decade, brain and autonomic nervous system activity measurement received increasing attention in the study of software engineering (SE). This paper presents a systematic literature review (SLR) to survey the existing NeuroSE literature. Based on a rigorous search protocol, we identified 89 papers (hereafter denoted as NeuroSE papers). We analyzed these papers to develop a comprehensive understanding of who had published NeuroSE research and classified the contributions according to their type. The 47 articles presenting completed empirical research were analyzed in detail. The SLR revealed that the number of authors publishing NeuroSE research is still relatively small. The thematic focus so far has been on code comprehension, while code inspection, programming, and bug fixing have been less frequently studied. NeuroSE publications primarily used methods related to brain activity measurement (particularly fMRI and EEG), while methods related to the measurement of autonomic nervous system activity (e.g., pupil dilation, heart rate, skin conductance) received less attention. We also present details of how the empirical research was conducted, including stimuli and independent and dependent variables, and discuss implications for future research. The body of NeuroSE literature is still small. Yet, high quality contributions exist constituting a valuable basis for future studies.}
}
@article{ALI201465,
title = {A systematic literature review on the industrial use of software process simulation},
journal = {Journal of Systems and Software},
volume = {97},
pages = {65-85},
year = {2014},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2014.06.059},
url = {https://www.sciencedirect.com/science/article/pii/S0164121214001502},
author = {Nauman Bin Ali and Kai Petersen and Claes Wohlin},
keywords = {Software process simulation, Systematic literature review, Evidence based software engineering},
abstract = {Context
Software process simulation modelling (SPSM) captures the dynamic behaviour and uncertainty in the software process. Existing literature has conflicting claims about its practical usefulness: SPSM is useful and has an industrial impact; SPSM is useful and has no industrial impact yet; SPSM is not useful and has little potential for industry.
Objective
To assess the conflicting standpoints on the usefulness of SPSM.
Method
A systematic literature review was performed to identify, assess and aggregate empirical evidence on the usefulness of SPSM.
Results
In the primary studies, to date, the persistent trend is that of proof-of-concept applications of software process simulation for various purposes (e.g. estimation, training, process improvement, etc.). They score poorly on the stated quality criteria. Also only a few studies report some initial evaluation of the simulation models for the intended purposes.
Conclusion
There is a lack of conclusive evidence to substantiate the claimed usefulness of SPSM for any of the intended purposes. A few studies that report the cost of applying simulation do not support the claim that it is an inexpensive method. Furthermore, there is a paramount need for improvement in conducting and reporting simulation studies with an emphasis on evaluation against the intended purpose.}
}
@article{ALABOOL2018161,
title = {Cloud service evaluation method-based Multi-Criteria Decision-Making: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {139},
pages = {161-188},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.01.038},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218300244},
author = {Hamzeh Alabool and Ahmad Kamil and Noreen Arshad and Deemah Alarabiat},
keywords = {Cloud computing service, Cloud service evaluation method, Multi-Criteria Decision-Making (MCDM), Evaluation theory, Systematic literature review},
abstract = {A substantial effort has been made to solve the cloud-service evaluation problem. Different Cloud Service Evaluation Methods (CSEMs) have been developed to address the problem. Cloud services are evaluated against multiple criteria, which leads to a Multi-Criteria Decision-Making (MCDM) problem. Yet, studies that assess, analyse, and summarize the unresolved problems and shortcomings of current CSEM-based MCDM are limited. In the existing review studies, only individual parts of CSEMs, rarely the full solution, are reviewed and examined. To investigate CSEMs comprehensively, we present a systematic literature review based on Evaluation Theory, a theory that generalizes six evaluation components, target, criteria, yardstick, data gathering techniques, synthesis techniques, and evaluation process. These six evaluation components and the CSEMs validation approach are the seven dimensions used to assess and analyse 77 papers published from 2006 to 2016. Sixteen research deficiencies were identified. The results confirm that the majority of the studies of the proposed CSEMs were either incomplete or lacked sufficient evidence. This research not only provides the relative strengths and weaknesses of the different CSEMs but also offers a basis for researchers and decision makers to develop improved CSEMs.}
}
@article{OZAKINCI2018216,
title = {Early software defect prediction: A systematic map and review},
journal = {Journal of Systems and Software},
volume = {144},
pages = {216-239},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.06.025},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218301213},
author = {Rana Özakıncı and Ayça Tarhan},
keywords = {Early defect prediction, Software defect, Software quality, Prediction model, Systematic mapping, Systematic literature review},
abstract = {Context
Software defect prediction is a trending research topic, and a wide variety of the published papers focus on coding phase or after. A limited number of papers, however, includes the prior (early) phases of the software development lifecycle (SDLC).
Objective
The goal of this study is to obtain a general view of the characteristics and usefulness of Early Software Defect Prediction (ESDP) models reported in scientific literature.
Method
A systematic mapping and systematic literature review study has been conducted. We searched for the studies reported between 2000 and 2016. We reviewed 52 studies and analyzed the trend and demographics, maturity of state-of-research, in-depth characteristics, success and benefits of ESDP models.
Results
We found that categorical models that rely on requirement and design phase metrics, and few continuous models including metrics from requirements phase are very successful. We also found that most studies reported qualitative benefits of using ESDP models.
Conclusion
We have highlighted the most preferred prediction methods, metrics, datasets and performance evaluation methods, as well as the addressed SDLC phases. We expect the results will be useful for software teams by guiding them to use early predictors effectively in practice, and for researchers in directing their future efforts.}
}
@article{KHAN2019396,
title = {Landscaping systematic mapping studies in software engineering: A tertiary study},
journal = {Journal of Systems and Software},
volume = {149},
pages = {396-436},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.12.018},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218302784},
author = {Muhammad Uzair Khan and Salman Sherin and Muhammad Zohaib Iqbal and Rubab Zahid},
keywords = {Tertiary study, Systematic mapping study, Secondary study, Survey, Software engineering},
abstract = {Context
A number of Systematic Mapping Studies (SMSs) that cover Software Engineering (SE) are reported in literature. Tertiary studies synthesize the secondary studies to provide a holistic view of an area.
Objectives
We synthesize SMSs in SE to provide insights into existing SE areas and to investigate the trends and quality of SMSs.
Methodology
We use Systematic Literature Review protocol to analyze and map the SMSs in SE, till August 2017, to SE Body of Knowledge (SWEBOK).
Results
We analyze 210 SMSs and results show that: (1) Software design and construction are most active areas in SE; (2) Some areas lack SMSs, including mathematical foundations, software configuration management, and SE tools; (3) The quality of SMSs is improving with time; (4) SMSs in journals have higher quality than SMSs in conferences and are cited more often; (5) Low quality in SMSs can be attributed to a lack of quality assessment in SMSs and not reporting information about the primary studies.
Conclusion
There is a potential for more SMSs in some SE areas. A number of SMSs do not provide the required information for an SMS, which leads to a low quality score.}
}
@article{DANEVA20141,
title = {Empirical research methodologies and studies in Requirements Engineering: How far did we come?},
journal = {Journal of Systems and Software},
volume = {95},
pages = {1-9},
year = {2014},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2014.06.035},
url = {https://www.sciencedirect.com/science/article/pii/S0164121214001460},
author = {Maya Daneva and Daniela Damian and Alessandro Marchetto and Oscar Pastor},
abstract = {Since the inception of the RE conference series (1992), both researchers and practitioners in the RE community have acknowledged the significance of empirical evaluation as an instrument to gain knowledge about various aspects of RE phenomena and the validity of our research results. A significant number of empirical studies have been conducted in the search for knowledge about RE problems as well as evidence of successful and less successful application of proposed solutions. This editorial presents the progress empirical RE research has made since 1992. Based on a search in the Scopus digital library, we report from an analysis of peer-reviewed systematic literature reviews and mapping studies to showcase major areas of RE research that use methods from the Empirical Software Engineering paradigm. We summarize prior empirical research in RE and introduce the contributors to this special issue on empirical research methodologies and studies in RE.}
}
@article{JABANGWE201898,
title = {Software engineering process models for mobile app development: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {145},
pages = {98-111},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.08.028},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218301638},
author = {Ronald Jabangwe and Henry Edison and Anh Nguyen Duc},
keywords = {Software engineering process models, Mobile application development, Mobile apps, Systematic literature review, Native apps, Hybrid apps},
abstract = {Context: An effective development model can help improve competitive advantage and shorten release cycles, which is vital in the fast paced environment of mobile app development. Objective: The aim with this paper is to provide an extensive review of existing mobile app development models. Method: The review is done by following a systematic literature review process. Also presented is an assessment of the usefulness and relevance to industry of the models based on a rigor and relevance framework. Results: 20 primary studies were identified, each with distinct models. Agile methods or state-based principles are commonly adopted across the models. Relatively little effort focuses on deployment, maintenance, project evaluation activities. Conclusion: The review reveals that the contexts in which the identified models are intended to be used vary. This benefits practitioners as they are able to select a model that suits their contexts. However, the usefulness in industry of most of the models, based on the contexts in which the models were evaluated, is questionable. There is a need for evaluating mobile app models in contexts that resemble realistic contexts. The review also calls for further research addressing special constraints of mobile apps, e.g., testing apps on multiple-platforms, user involvement in release planning and continuous deployment.}
}
@article{KARG2011415,
title = {A systematic literature review of software quality cost research},
journal = {Journal of Systems and Software},
volume = {84},
number = {3},
pages = {415-427},
year = {2011},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2010.11.904},
url = {https://www.sciencedirect.com/science/article/pii/S0164121210003146},
author = {Lars M. Karg and Michael Grottke and Arne Beckhaus},
keywords = {Prevention appraisal failure cost scheme, Software development, Systematic literature review, Quality costs},
abstract = {Abstract
Software quality costs have not received as much attention from the research community as other economic aspects of software development. Over the last three decades, a number of articles on this topic have appeared in a range of journals, but comprehensive overviews of this body of research are not available. For the detailed review of software quality cost research presented in this article, we collect 87 articles published between 1980 and 2009 in 60 leading computing journals. We study the distribution of these articles across research disciplines and journals as well as over time. Moreover, we identify the predominant researchers in the software quality cost domain and the related research clusters. We also classify the articles according to three properties, namely, research topic, research scope, and research approach. This categorization enables us to identify aspects emphasized by previous research on software quality costs and to point out promising future research directions. Our review shows that prevention costs have gained the least attention, in spite of their big cost impact. It also reveals that only one article has targeted multiple companies. Further, we observe that many articles do not empirically validate their findings. This is especially true for those articles dealing with an entire firm.}
}
@article{VASCONCELLOS201745,
title = {Approaches to strategic alignment of software process improvement: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {123},
pages = {45-63},
year = {2017},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.09.030},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216301893},
author = {Francisco J.S. Vasconcellos and Geraldo B. Landre and José Adson O.G. Cunha and Juliano L. Oliveira and Ronaldo A. Ferreira and Auri M.R. Vincenzi},
keywords = {Software process improvement, Strategic alignment, Business alignment, Systematic literature review},
abstract = {Context: Software process improvement (SPI) aims to increase the effectiveness of a software organization. Many studies indicate that the strategic alignment is a critical factor for the SPI success. However, little is known about practical approaches to achieving and maintaining such alignment. Objective: The goal of this study is to evaluate the validation evidence of the existing approaches to the strategic alignment of SPI. Method: We develop a search protocol that combines database search and snowballing to perform the systematic literature review and evaluate empirical studies by applying rigor and relevance criteria. To evaluate the efficiency of our protocol, we use a “quasi-gold standard” to compute the sensitivity and precision of the search. Result: We identified 30 studies (18 empirical) and 19 approaches to strategic alignment of SPI from 495 retrieved studies. Only three out of the 18 empirical studies were rated as high in the categories rigor and relevance, suggesting the need for a stronger validation of the approaches. Conclusion: We conclude that the lack of empirical validation indicates that the results of the existing approaches have not been adequately transferred to practitioners yet, calling for more rigorous studies on the subject.}
}
@article{MERTZ2021110963,
title = {Tigris: A DSL and framework for monitoring software systems at runtime},
journal = {Journal of Systems and Software},
volume = {177},
pages = {110963},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.110963},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221000601},
author = {Jhonny Mertz and Ingrid Nunes},
keywords = {Monitoring, Logging, Execution trace, Sampling, Caching, Performance},
abstract = {The understanding of the behavioral aspects of a software system is an essential enabler for many software engineering activities, such as adaptation. This involves collecting runtime data from the system so that it is possible to analyze the collected data to guide actions upon the system. Consequently, software monitoring imposes practical challenges because it is often done by intercepting the system execution and recording gathered information. Such monitoring may degrade the performance and disrupt the system execution to unacceptable levels. In this paper, we introduce a two-phase monitoring approach to support the monitoring step in adaptive systems. The first phase collects lightweight coarse-grained information and identifies relevant parts of the software that should be monitored in detail based on a provided domain-specific language. This language is informed by a systematic literature review. The second phase collects relevant and fine-grained information needed for deciding whether and how to adapt the managed system. Our approach is implemented as a framework, called Tigris, that can be seamlessly integrated into existing software systems to support monitoring-based activities. To validate our proposal, we instantiated Tigris to support an application-level caching approach, which adapts caching decisions of a software system at runtime to improve its performance.}
}
@article{MENDES2020110607,
title = {When to update systematic literature reviews in software engineering},
journal = {Journal of Systems and Software},
volume = {167},
pages = {110607},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110607},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220300856},
author = {Emilia Mendes and Claes Wohlin and Katia Felizardo and Marcos Kalinowski},
keywords = {Systematic literature review update, Systematic literature reviews, Software engineering},
abstract = {[Context] Systematic Literature Reviews (SLRs) have been adopted by the Software Engineering (SE) community for approximately 15 years to provide meaningful summaries of evidence on several topics. Many of these SLRs are now potentially outdated, and there are no systematic proposals on when to update SLRs in SE. [Objective] The goal of this paper is to provide recommendations on when to update SLRs in SE. [Method] We evaluated, using a three-step approach, a third-party decision framework (3PDF) employed in other fields, to decide whether SLRs need updating. First, we conducted a literature review of SLR updates in SE and contacted the authors to obtain their feedback relating to the usefulness of the 3PDF within the context of SLR updates in SE. Second, we used these authors’ feedback to see whether the framework needed any adaptation; none was suggested. Third, we applied the 3PDF to the SLR updates identified in our literature review. [Results] The 3PDF showed that 14 of the 20 SLRs did not need updating. This supports the use of a decision support mechanism (such as the 3PDF) to help the SE community decide when to update SLRs. [Conclusions] We put forward that the 3PDF should be adopted by the SE community to keep relevant evidence up to date and to avoid wasting effort with unnecessary updates.}
}
@article{STAPLES20071425,
title = {Experiences using systematic review guidelines},
journal = {Journal of Systems and Software},
volume = {80},
number = {9},
pages = {1425-1437},
year = {2007},
note = {Evaluation and Assessment in Software Engineering},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2006.09.046},
url = {https://www.sciencedirect.com/science/article/pii/S0164121206002962},
author = {Mark Staples and Mahmood Niazi},
keywords = {Systematic review, Empirical software engineering},
abstract = {Systematic review is a method to identify, assess and analyse published primary studies to investigate research questions. We critique recently published guidelines for performing systematic reviews on software engineering, and comment on systematic review generally with respect to our experience conducting one. Overall we recommend the guidelines. We recommend researchers clearly and narrowly define research questions to reduce overall effort, and to improve selection and data extraction. We suggest that “complementary” research questions can help clarify the main questions and define selection criteria. We show our project timeline, and discuss possibilities for automating and increasing the acceptance of systematic review.}
}
@article{PEREIRA2021111044,
title = {Learning software configuration spaces: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {182},
pages = {111044},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111044},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221001412},
author = {Juliana Alves Pereira and Mathieu Acher and Hugo Martin and Jean-Marc Jézéquel and Goetz Botterweck and Anthony Ventresque},
keywords = {Systematic literature review, Software product lines, Machine learning, Configurable systems},
abstract = {Most modern software systems (operating systems like Linux or Android, Web browsers like Firefox or Chrome, video encoders like ffmpeg, x264 or VLC, mobile and cloud applications, etc.) are highly configurable. Hundreds of configuration options, features, or plugins can be combined, each potentially with distinct functionality and effects on execution time, security, energy consumption, etc. Due to the combinatorial explosion and the cost of executing software, it is quickly impossible to exhaustively explore the whole configuration space. Hence, numerous works have investigated the idea of learning it from a small sample of configurations’ measurements. The pattern “sampling, measuring, learning” has emerged in the literature, with several practical interests for both software developers and end-users of configurable systems. In this systematic literature review, we report on the different application objectives (e.g., performance prediction, configuration optimization, constraint mining), use-cases, targeted software systems, and application domains. We review the various strategies employed to gather a representative and cost-effective sample. We describe automated software techniques used to measure functional and non-functional properties of configurations. We classify machine learning algorithms and how they relate to the pursued application. Finally, we also describe how researchers evaluate the quality of the learning process. The findings from this systematic review show that the potential application objective is important; there are a vast number of case studies reported in the literature related to particular domains or software systems. Yet, the huge variant space of configurable systems is still challenging and calls to further investigate the synergies between artificial intelligence and software engineering.}
}
@article{GIAIMO2020110781,
title = {Continuous experimentation and the cyber–physical systems challenge: An overview of the literature and the industrial perspective},
journal = {Journal of Systems and Software},
volume = {170},
pages = {110781},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110781},
url = {https://www.sciencedirect.com/science/article/pii/S016412122030193X},
author = {Federico Giaimo and Hugo Andrade and Christian Berger},
keywords = {Continuous Experimentation, Cyber–physical systems, Software engineering},
abstract = {Context:
New software development patterns are emerging aiming at accelerating the process of delivering value. One is Continuous Experimentation, which allows to systematically deploy and run instrumented software variants during development phase in order to collect data from the field of application. While currently this practice is used on a daily basis on web-based systems, technical difficulties challenge its adoption in fields where computational resources are constrained, e.g., cyber–physical systems and the automotive industry.
Objective:
This paper aims at providing an overview of the engagement on the Continuous Experimentation practice in the context of cyber–physical systems.
Method:
A systematic literature review has been conducted to investigate the link between the practice and the field of application. Additionally, an industrial multiple case study is reported.
Results:
The study presents the current state-of-the-art regarding Continuous Experimentation in the field of cyber–physical systems. The current perspective of Continuous Experimentation in industry is also reported.
Conclusions:
The field has not reached maturity yet. More conceptual analyses are found than solution proposals and the state-of-practice is yet to be achieved. However it is expected that in time an increasing number of solutions will be proposed and validated.}
}
@article{BRERETON2007571,
title = {Lessons from applying the systematic literature review process within the software engineering domain},
journal = {Journal of Systems and Software},
volume = {80},
number = {4},
pages = {571-583},
year = {2007},
note = {Software Performance},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2006.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S016412120600197X},
author = {Pearl Brereton and Barbara A. Kitchenham and David Budgen and Mark Turner and Mohamed Khalil},
keywords = {Systematic literature review, Empirical software engineering},
abstract = {A consequence of the growing number of empirical studies in software engineering is the need to adopt systematic approaches to assessing and aggregating research outcomes in order to provide a balanced and objective summary of research evidence for a particular topic. The paper reports experiences with applying one such approach, the practice of systematic literature review, to the published studies relevant to topics within the software engineering domain. The systematic literature review process is summarised, a number of reviews being undertaken by the authors and others are described and some lessons about the applicability of this practice to software engineering are extracted. The basic systematic literature review process seems appropriate to software engineering and the preparation and validation of a review protocol in advance of a review activity is especially valuable. The paper highlights areas where some adaptation of the process to accommodate the domain-specific characteristics of software engineering is needed as well as areas where improvements to current software engineering infrastructure and practices would enhance its applicability. In particular, infrastructure support provided by software engineering indexing databases is inadequate. Also, the quality of abstracts is poor; it is usually not possible to judge the relevance of a study from a review of the abstract alone.}
}
@article{RANI2022111515,
title = {A decade of code comment quality assessment: A systematic literature review},
journal = {Journal of Systems and Software},
pages = {111515},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111515},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222001911},
author = {Pooja Rani and Arianna Blasi and Nataliia Stulova and Sebastiano Panichella and Alessandra Gorla and Oscar Nierstrasz},
keywords = {Code comments, Documentation quality, Systematic literature review},
abstract = {Code comments are important artifacts in software systems and play a paramount role in many software engineering (SE) tasks related to maintenance and program comprehension. However, while it is widely accepted that high quality matters in code comments just as it matters in source code, assessing comment quality in practice is still an open problem. First and foremost, there is no unique definition of quality when it comes to evaluating code comments. The few existing studies on this topic rather focus on specific attributes of quality that can be easily quantified and measured. Existing techniques and corresponding tools may also focus on comments bound to a specific programming language, and may only deal with comments with specific scopes and clear goals (e.g., Javadoc comments at the method level, or in-body comments describing TODOs to be addressed). In this paper, we present a Systematic Literature Review (SLR) of the last decade of research in SE to answer the following research questions: (i) What types of comments do researchers focus on when assessing comment quality? (ii) What quality attributes (QAs) do they consider? (iii) Which tools and techniques do they use to assess comment quality?, and (iv) How do they evaluate their studies on comment quality assessment in general? Our evaluation, based on the analysis of 2353 papers and the actual review of 47 relevant ones, shows that (i) most studies and techniques focus on comments in Java code, thus may not be generalizable to other languages, and (ii) the analyzed studies focus on four main QAs of a total of 21 QAs identified in the literature, with a clear predominance of checking consistency between comments and the code. We observe that researchers rely on manual assessment and specific heuristics rather than the automated assessment of the comment quality attributes, with evaluations often involving surveys of students and the authors of the original studies but rarely professional developers.}
}
@article{MATALONGA20171,
title = {Characterizing testing methods for context-aware software systems: Results from a quasi-systematic literature review},
journal = {Journal of Systems and Software},
volume = {131},
pages = {1-21},
year = {2017},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2017.05.048},
url = {https://www.sciencedirect.com/science/article/pii/S016412121730095X},
author = {Santiago Matalonga and Felyppe Rodrigues and Guilherme Horta Travassos},
keywords = {Context-aware, Software testing, Test case design, Systematic literature review},
abstract = {Context-Aware Software Systems (CASS) use environmental information to provide better service to the systems’ actors to fulfill their goals. Testing of ubiquitous software systems can be challenging since it is unlikely that, while designing the test cases, the tester can identify all possible context variations. A quasi-Systematic Literature Review has been undertaken to characterize the methods usually used for testing CASS. The analysis and generation of knowledge in this work rely on classifying the extracted information. Established taxonomies of software testing and context-aware were used to characterize and interpret the findings. The results show that, although it is possible to observe the utilization of some software testing methods, few empirical studies are evaluating such methods when testing CASS. The selected technical literature conveys a lack of consensus on the understanding of context and CASS, and on the meaning of software testing. Furthermore, context variation in CASS has only been partially addressed by the identified approaches. They either rely on simulating context or in fixing the values of context variables during testing. We argue that the tests of context-aware software systems need to deal with the diversity of context instead of mitigating their effects.}
}
@article{IDRI2016151,
title = {Systematic literature review of ensemble effort estimation},
journal = {Journal of Systems and Software},
volume = {118},
pages = {151-175},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.05.016},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216300450},
author = {Ali Idri and Mohamed Hosni and Alain Abran},
keywords = {Systematic literature review, Software development effort estimation, Ensemble effort estimation},
abstract = {The need to overcome the weaknesses of single estimation techniques for prediction tasks has given rise to ensemble methods in software development effort estimation (SDEE). An ensemble effort estimation (EEE) technique combines several of the single/classical models found in the SDEE literature. However, to the best of our knowledge, no systematic review has yet been performed with a focus on the use of EEE techniques in SDEE. The purpose of this review is to analyze EEE techniques from six viewpoints: single models used to construct ensembles, ensemble estimation accuracy, rules used to combine single estimates, accuracy comparison of EEE techniques with single models, accuracy comparison between EEE techniques and methodologies used to construct ensemble methods. We performed a systematic review of EEE studies published between 2000 and 2016, and we selected 24 of them to address the questions raised in this review. We found that EEE techniques may be separated into two types: homogeneous and heterogeneous, and that the machine learning single models are the most frequently employed in constructing EEE techniques. We also found that EEE techniques usually yield acceptable estimation accuracy, and in fact are more accurate than single models.}
}
@article{FARSHIDI2020110714,
title = {Capturing software architecture knowledge for pattern-driven design},
journal = {Journal of Systems and Software},
volume = {169},
pages = {110714},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110714},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220301552},
author = {Siamak Farshidi and Slinger Jansen and Jan Martijn {van der Werf}},
keywords = {Architectural patterns, Architectural styles, Quality attributes, Design decisions, Knowledge acquisition},
abstract = {Context:
Software architecture is a knowledge-intensive field. One mechanism for storing architecture knowledge is the recognition and description of architectural patterns. Selecting architectural patterns is a challenging task for software architects, as knowledge about these patterns is scattered among a wide range of literature.
Method:
We report on a systematic literature review, intending to build a decision model for the architectural pattern selection problem. Moreover, twelve experienced practitioners at software-producing organizations evaluated the usability and usefulness of the extracted knowledge.
Results:
An overview is provided of 29 patterns and their effects on 40 quality attributes. Furthermore, we report in which systems the 29 patterns are applied and in which combinations. The practitioners confirmed that architectural knowledge supports software architects with their decision-making process to select a set of patterns for a new problem. We investigate the potential trends among architects to select patterns.
Conclusion:
With the knowledge available, architects can more rapidly select and eliminate combinations of patterns to design solutions. Having this knowledge readily available supports software architects in making more efficient and effective design decisions that meet their quality concerns.}
}
@article{AUCH2020110669,
title = {Similarity-based analyses on software applications: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {168},
pages = {110669},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110669},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220301278},
author = {Maximilian Auch and Manuel Weber and Peter Mandl and Christian Wolff},
keywords = {Software similarity, Secondary study, Machine learning},
abstract = {In empirical studies on processes, practices, and techniques of software engineering, automation and machine learning are gaining popularity. In order to extract knowledge from existing software projects, a sort of similarity analysis is often performed using different methodologies, data and metadata. This systematic literature review focuses therefore on existing approaches of similarity-, categorization- and relevance-based analysis on software applications. In total, 136 relevant publications and patents were identified between 2002 and 2019 according to the established inclusion and exclusion criteria, which perform a calculation of software similarity in general or to support certain software engineering phases.}
}
@article{GONCALVES20181,
title = {A Systematic Literature Review of iStar extensions},
journal = {Journal of Systems and Software},
volume = {137},
pages = {1-33},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2017.11.023},
url = {https://www.sciencedirect.com/science/article/pii/S0164121217302741},
author = {Enyo Gonçalves and Jaelson Castro and João Araújo and Tiago Heineck},
keywords = {Systematic Literature Review, Goal modelling, iStar, Modelling language extensions},
abstract = {iStar is a general-purpose goal-based modelling language used to model requirements at early and late phases of software development. It has been used in industrial and academic projects. Often the language is extended to incorporate new constructs related to an application area. The language is currently undergoing standardisation, so several studies have focused on the analysis of iStar variations to identify the similarities and defining a core iStar. However, we believe it will continue to be extended and it is important to understand how iStar is extended. This paper contributes to this purpose through the identification and analysis of the existing extensions and its constructs. A Systematic Literature Review was conducted to guide identification and analysis. The results point to 96 papers and 307 constructs proposed. The extensions and constructs were analysed according to well-defined questions in three dimensions: a general analysis; model-based analysis (to characterise the extensions from semantic and syntactic definitions); and a third dimension related to semiotic clarity. The application area targeted by the iStar extensions and their evolutions are presented as results of our analysis. The results point to the need for more complete, consistent and careful development of iStar extensions. The paper concludes with some discussions and future directions for this research field.}
}
@article{BIDLAKE2020110565,
title = {Systematic literature review of empirical studies on mental representations of programs},
journal = {Journal of Systems and Software},
volume = {165},
pages = {110565},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110565},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220300467},
author = {Leah Bidlake and Eric Aubanel and Daniel Voyer},
keywords = {Mental representations, Program comprehension, Systematic literature review},
abstract = {Programmers are frequently tasked with modifying, enhancing, and extending applications. To perform these tasks, programmers must understand existing code by forming mental representations. Empirical research is required to determine the mental representations constructed during program comprehension to inform the development of programming languages, instructional practices, and tools. To make recommendations for future work a systematic literature review was conducted that summarizes the empirical research on mental representations formed during program comprehension, how the methods and tasks have changed over time, and the research contributions. The data items included in the systematic review are empirical studies of programmers that investigated the comprehension and internal representation of code written in a formal programming language. The eligibility criteria used in the review were meant to extract studies with a focus on knowledge representation as opposed to knowledge utilization. The results revealed a lack of incremental research and a dramatic decline in the research meaning that newly developed or popularized languages and paradigms have not been a part of the research reviewed. Accordingly, we argue that there needs to be a resurgence of empirical research on the psychology of programming to inform the design of tools and languages, especially in new and emerging paradigms.}
}
@article{LI20132371,
title = {On evaluating commercial Cloud services: A systematic review},
journal = {Journal of Systems and Software},
volume = {86},
number = {9},
pages = {2371-2393},
year = {2013},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2013.04.021},
url = {https://www.sciencedirect.com/science/article/pii/S0164121213000915},
author = {Zheng Li and He Zhang and Liam O’Brien and Rainbow Cai and Shayne Flint},
keywords = {Cloud Computing, Cloud service evaluation, Systematic literature review},
abstract = {Background
Cloud Computing is increasingly booming in industry with many competing providers and services. Accordingly, evaluation of commercial Cloud services is necessary. However, the existing evaluation studies are relatively chaotic. There exists tremendous confusion and gap between practices and theory about Cloud services evaluation.
Aim
To facilitate relieving the aforementioned chaos, this work aims to synthesize the existing evaluation implementations to outline the state-of-the-practice and also identify research opportunities in Cloud services evaluation.
Method
Based on a conceptual evaluation model comprising six steps, the systematic literature review (SLR) method was employed to collect relevant evidence to investigate the Cloud services evaluation step by step.
Results
This SLR identified 82 relevant evaluation studies. The overall data collected from these studies essentially depicts the current practical landscape of implementing Cloud services evaluation, and in turn can be reused to facilitate future evaluation work.
Conclusions
Evaluation of commercial Cloud services has become a world-wide research topic. Some of the findings of this SLR identify several research gaps in the area of Cloud services evaluation (e.g., Elasticity and Security evaluation of commercial Cloud services could be a long-term challenge), while some other findings suggest the trend of applying commercial Cloud services (e.g., compared with PaaS, IaaS seems more suitable for customers and is particularly important in industry). This SLR study itself also confirms some previous experiences and records new evidence-based software engineering (EBSE) lessons.}
}
@article{HRON2022111110,
title = {Why and how is Scrum being adapted in practice: A systematic review},
journal = {Journal of Systems and Software},
volume = {183},
pages = {111110},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111110},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221002077},
author = {Michal Hron and Nikolaus Obwegeser},
keywords = {Scrum, Agile development, Systematic literature review, Information systems development},
abstract = {Scrum, recognized today as the most popular agile development methodology, has been used in a wide range of settings and for varying purposes, in- and outside of the traditional software development context. The use of Scrum in non-traditional settings and for different needs led to a considerable corpus of academic literature that investigates, presents, and discusses modifications to the original method, aimed to make it fit such novel forms of application. Based on a large-scale review of extant literature, this study systematically analyses why and how Scrum was reportedly modified in different instances and contributes with a synthesis that can serve as a basis for a more systematic approach to future research and practice. We explicate nine common modification objectives for change (e.g., attaining high performance, non-standard contexts, distributed development) mapped against seven generic modification strategies (e.g., method guidance, new procedures, or artifacts). Building on our extensive literature analysis we highlight research gaps and identify promising areas for future research.}
}
@article{GAROUSI201965,
title = {Aligning software engineering education with industrial needs: A meta-analysis},
journal = {Journal of Systems and Software},
volume = {156},
pages = {65-83},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.06.044},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219301347},
author = {Vahid Garousi and Görkem Giray and Eray Tüzün and Cagatay Catal and Michael Felderer},
keywords = {Software engineering education, Industry needs, Important skills, Knowledge gap, Systematic literature review (SLR), Meta-analysis},
abstract = {Context
According to various reports, many software engineering (SE) graduates often face difficulties when beginning their careers, which is mainly due to misalignment of the skills learned in university education with what is needed in the software industry.
Objective
Our objective is to perform a meta-analysis to aggregate the results of the studies published in this area to provide a consolidated view on how to align SE education with industry needs, to identify the most important skills and also existing knowledge gaps.
Method
To synthesize the body of knowledge, we performed a systematic literature review (SLR), in which we systematically selected a pool of 35 studies and then conducted a meta-analysis using data extracted from those studies.
Results
Via a meta-analysis and using data from 13 countries and over 4,000 data points, highlights of the SLR include: (1) software requirements, design, and testing are the most important skills; and (2) the greatest knowledge gaps are in configuration management, SE models and methods, SE process, design (and architecture), as well as in testing.
Conclusion
This paper provides implications for both educators and hiring managers by listing the most important SE skills and the knowledge gaps in the industry.}
}
@article{DASILVA2012216,
title = {Towards understanding the underlying structure of motivational factors for software engineers to guide the definition of motivational programs},
journal = {Journal of Systems and Software},
volume = {85},
number = {2},
pages = {216-226},
year = {2012},
note = {Special issue with selected papers from the 23rd Brazilian Symposium on Software Engineering},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2010.12.017},
url = {https://www.sciencedirect.com/science/article/pii/S0164121210003390},
author = {Fabio Q.B. {da Silva} and A. César C. França},
keywords = {Motivation, People management, Software development, Empirical software engineering},
abstract = {Aim
In this article, factors influencing the motivation of software engineers is studied with the goal of guiding the definition of motivational programs.
Method
Using a set of 20 motivational factors compiled in a systematic literature review and a general theory of motivation, a survey questionnaire was created to evaluate the influence of these factors on individual motivation. Then, the questionnaire was applied on a semi-random sample of 176 software engineers from 20 software companies located in Recife-PE, Brazil.
Results
The survey results show the actual level of motivation for each motivator in the target population. Using principal component analysis on the values of all motivators, a five factor structure was identified and used to propose a guideline for the creation of motivational programs for software engineers.
Conclusions
The five factor structure provides an intuitive categorization for the set of variables and can be used to explain other motivational models presented in the literature. This contributes to a better understanding of motivation in software engineering.}
}
@article{KOSAR2018439,
title = {A Systematic Mapping Study driven by the margin of error},
journal = {Journal of Systems and Software},
volume = {144},
pages = {439-449},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.06.078},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218301353},
author = {Tomaž Kosar and Sudev Bohra and Marjan Mernik},
keywords = {Software engineering, Systematic review, Systematic Mapping Study, Reliability, Margin of error},
abstract = {Until recently, many Systematic Literature Reviews (SLRs) and Systematic Mapping Studies (SMSs) have been proposed. However, when SMS is performed on a broad topic with a large amount of primary studies, the cost of assessment of all primary studies requires unjustified resources. In this paper, a new approach is introduced for performing SMSs, called SMS driven by the margin of error. The main objective of the described work was to decrease the assessment cost of primary studies by stopping the process of classification of primary studies when enough evidence has been collected. We introduced a statistical approach with random sampling and a margin of error into the design of SMSs when a topic under discussion is broad with a large number of primary studies. In this paper, SMS driven by the margin of error was applied on three different use cases: SMS on Domain-Specific Languages, SMS on Template-based Code Generation, and SMS on Software Reliability Modeling, where it was shown that the proposed approach reduced the cost of assessing primary studies and quantified the reliability of SMS.}
}
@article{ZIELSKE2022111328,
title = {Agile methods used by traditional logistics companies and logistics start-ups: a systematic literature review},
journal = {Journal of Systems and Software},
volume = {190},
pages = {111328},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111328},
url = {https://www.sciencedirect.com/science/article/pii/S016412122200070X},
author = {Malena Zielske and Tobias Held},
keywords = {Agile methods, Logistics, Traditional companies, Start-ups, Literature review},
abstract = {An increasing number of companies and start-ups aims to enhance their agility through the use of agile methods and practices in order to cope with raising product development and project complexity and quickly changing requirements (Laanti et al. (2011); Schön et al. (2017); Könnölä et al. (2016)). Especially in the logistics industry, which is known as a slow adaptor to changes in general but regarding new innovations in particular (Cockburn and Highsmith (2001); Beck (2000); Abbas et al. (2008)), it is relevant to see how these companies cope with change. Opposed to that, logistics start-ups seem to be able to create customer value with disruptive products and services. This paper aims to capture the current state of the literature related to the use of agile methods and practices in established logistics companies and logistics start-ups. Of particular interest will be analyzing which methods and practices are used, what specific challenges established logistics companies and logistics start-ups aim to solve with these agile methods and practices, and the difficulties they face in doing so. A systematic literature review (SLR) with an extensive quality assessment of the included nine studies was conducted. After the analysis, insights on the following points were derived: use of agile methods and practices, the challenges that are solved with these methods and practices, and difficulties in the application of these methods and practices. Future research should deepen these findings with, for instance, qualitative data from real-life cases of logistics companies and start-ups. The originality of the SLR presented lies in its contribution to the largely unexplored field of agility in traditional logistics companies and logistics start-ups, as well as its assessment of the state-of-the-art literature analyzed.}
}
@article{OCHOA2018511,
title = {A systematic literature review on the semi-automatic configuration of extended product lines},
journal = {Journal of Systems and Software},
volume = {144},
pages = {511-532},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.07.054},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218301511},
author = {Lina Ochoa and Oscar González-Rojas and Alves Pereira Juliana and Harold Castro and Gunter Saake},
keywords = {Extended product line, Product configuration, Systematic literature review},
abstract = {Product line engineering has become essential in mass customisation given its ability to reduce production costs and time to market, and to improve product quality and customer satisfaction. In product line literature, mass customisation is known as product configuration. Currently, there are multiple heterogeneous contributions in the product line configuration domain. However, a secondary study that shows an overview of the progress, trends, and gaps faced by researchers in this domain is still missing. In this context, we provide a comprehensive systematic literature review to discover which approaches exist to support the configuration process of extended product lines and how these approaches perform in practice. Extend product lines consider non-functional properties in the product line modelling. We compare and classify a total of 66 primary studies from 2000 to 2016. Mainly, we give an in-depth view of techniques used by each work, how these techniques are evaluated and their main shortcomings. As main results, our review identified (i) the need to improve the quality of the evaluation of existing approaches, (ii) a lack of hybrid solutions to support multiple configuration constraints, and (iii) a need to improve scalability and performance conditions.}
}
@article{MEHTA2022111345,
title = {Maximizing integrative learning in software development teams: A systematic review of key drivers and future research agenda},
journal = {Journal of Systems and Software},
volume = {190},
pages = {111345},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111345},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222000838},
author = {Anju Mehta and Nikhil Mehta and Ishaan Bindal},
keywords = {Team integrative learning, Software development teams, Social capital, Boundary spanning, Team design, Literature review},
abstract = {Software development is a complex phenomenon that requires software teams to integrate diverse knowledge and expertise to provide innovative solutions. A critical success factor for software teams is their integrative learning capability which is driven by multiple factors. We systematically review and synthesize extant literature to identify critical antecedents of integrative learning in software teams and uncover knowledge gaps to inform future research. Searching multiple databases, 447 papers were identified, of which 32 were selected for the final analysis after a rigorous data extraction process. We performed open and axial coding and affinity diagramming to thematically analyze each study for antecedents associated with integrative learning. We also triangulated our results by content analyzing the studies using a software-based text analysis tool. The findings indicate five crucial drivers of integrative learning in software teams: social harmony, process agility, team design, technological maturity, and project environment. The study also highlights the value of recognizing the inter-team and intra-team contexts in team learning. Based on the study findings, we propose a model of integrative learning in software teams, discuss future research agendas, and offer practical insights and recommendations to software professionals.}
}
@article{WANG201859,
title = {Requirements traceability technologies and technology transfer decision support: A systematic review},
journal = {Journal of Systems and Software},
volume = {146},
pages = {59-79},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218301754},
author = {Bangchao Wang and Rong Peng and Yuanbang Li and Han Lai and Zhuo Wang},
keywords = {Requirements traceability technology, Technology transfer, Systematic literature review, Requirements traceability challenges, Quality assessment},
abstract = {Requirements traceability (RT) is a core activity in Requirements Engineering. Various types of RT technologies have been extensively studied for decades. In this paper, we present a systematic literature review from 114 papers between 2006 and 2016 on RT techniques. We summarized 10 major challenges in current RT activities, and categorized existing RT techniques into 6 groups and 25 sub-groups. Moreover, we built mapping relations between these challenges and techniques, and identified 7 potential future research directions. Based on 83 empirical studies, the evaluations for technology transfer are conducted. The main conclusions are: (1) The “trustworthy” and “automated” challenges are the most widely investigated ones, while “scalable”, “coordinated”, “dynamic” and “lightweight” challenges receive much less attention; (2) “Trace link generation”, especially information retrieval-based (IR-based) methods, are the most studied techniques; (3) IR-based methods have the most potential to be adopted by industry, as they have been validated from multiple viewpoints; (4) Seven promising future research directions are identified, which include developing scalable, dynamic and lightweight tracing techniques, introducing new approaches in other disciplines to meet the RT challenges, improving the express ability of trace links, promoting the industry adoption of RT technologies and developing new techniques to support developers’ coordination.}
}
@article{MERINO2018165,
title = {A systematic literature review of software visualization evaluation},
journal = {Journal of Systems and Software},
volume = {144},
pages = {165-180},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.06.027},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218301237},
author = {L. Merino and M. Ghafari and C. Anslow and O. Nierstrasz},
keywords = {Software visualisation, Evaluation, Literature review},
abstract = {Context:Software visualizations can help developers to analyze multiple aspects of complex software systems, but their effectiveness is often uncertain due to the lack of evaluation guidelines. Objective: We identify common problems in the evaluation of software visualizations with the goal of formulating guidelines to improve future evaluations. Method:We review the complete literature body of 387 full papers published in the SOFTVIS/VISSOFT conferences, and study 181 of those from which we could extract evaluation strategies, data collection methods, and other aspects of the evaluation. Results:Of the proposed software visualization approaches, 62% lack a strong evaluation. We argue that an effective software visualization should not only boost time and correctness but also recollection, usability, engagement, and other emotions. Conclusion:We call on researchers proposing new software visualizations to provide evidence of their effectiveness by conducting thorough (i) case studies for approaches that must be studied in situ, and when variables can be controlled, (ii) experiments with randomly selected participants of the target audience and real-world open source software systems to promote reproducibility and replicability. We present guidelines to increase the evidence of the effectiveness of software visualization approaches, thus improving their adoption rate.}
}
@article{ASSYNE2022111183,
title = {The state of research on software engineering competencies: A systematic mapping study},
journal = {Journal of Systems and Software},
volume = {185},
pages = {111183},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111183},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221002648},
author = {Nana Assyne and Hadi Ghanbari and Mirja Pulkkinen},
keywords = {Software engineering, Software development, Competence, Competencies, Essential competencies, Mapping study, Systematic Literature Review},
abstract = {Considering the critical role of software in modern societies, we face an urgent need to educate more competent software professionals. Software engineering competencies (SEC) are considered the backbone of successfully developing software products. Consequently, SEC has become a hotspot for software engineering research and practice. Although scientific literature on SEC is not lacking, to our knowledge, a comprehensive overview of the current state of SEC research is missing. To that end, we conducted an extensive and systematic review of the SEC literature. We provide an overview of the current state of research on SEC, with a particular focus on common SEC research areas. In addition to reporting the available SEC models and frameworks, we compile a list of 49 unique essential competencies of software professionals. Finally, we highlight several gaps in the literature that deserve further research. In particular, we call for a better understanding of how the essential competencies of software professionals change over time, as well as fresh accounts of the essential competencies of software professionals. Additionally, considering recent shifts toward Agile and DevOps methods, future research must explore the competencies required for developing software products in modern development environments.}
}
@article{LENARDUZZI2021110827,
title = {A systematic literature review on Technical Debt prioritization: Strategies, processes, factors, and tools},
journal = {Journal of Systems and Software},
volume = {171},
pages = {110827},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110827},
url = {https://www.sciencedirect.com/science/article/pii/S016412122030220X},
author = {Valentina Lenarduzzi and Terese Besker and Davide Taibi and Antonio Martini and Francesca {Arcelli Fontana}},
keywords = {Technical Debt, Technical Debt prioritization, Systematic Literature Review},
abstract = {Background
Software companies need to manage and refactor Technical Debt issues. Therefore, it is necessary to understand if and when refactoring of Technical Debt should be prioritized with respect to developing features or fixing bugs.
Objective
The goal of this study is to investigate the existing body of knowledge in software engineering to understand what Technical Debt prioritization approaches have been proposed in research and industry.
Method
We conducted a Systematic Literature Review of 557 unique papers published until 2020, following a consolidated methodology applied in software engineering. We included 44 primary studies.
Results
Different approaches have been proposed for Technical Debt prioritization, all having different goals and proposing optimization regarding different criteria. The proposed measures capture only a small part of the plethora of factors used to prioritize Technical Debt qualitatively in practice. We present an impact map of such factors. However, there is a lack of empirical and validated set of tools.
Conclusion
We observed that Technical Debt prioritization research is preliminary and there is no consensus on what the important factors are and how to measure them. Consequently, we cannot consider current research conclusive. In this paper, we therefore outline different directions for necessary future investigations.}
}
@article{SARI2019200,
title = {A systematic literature review on crowdsourcing in software engineering},
journal = {Journal of Systems and Software},
volume = {153},
pages = {200-219},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.04.027},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219300779},
author = {Aslı Sarı and Ayşe Tosun and Gülfem Işıklar Alptekin},
keywords = {Crowdsourcing, Crowdsourcing in software engineering, Systematic literature review, Empirical software engineering},
abstract = {Background
Crowdsourcing outsources a task to large groups of people by open call format, and it recently plays significant role for software practitioners.
Aim
The purpose of this study is to conduct a comprehensive overview on crowdsourcing in software engineering (CSE), concerning business models, tools, platforms, software development processes, and software economics.
Method
We conducted a systematic literature review on CSE. We identified 158 relevant studies and 6 secondary studies. We further reviewed 67 primary studies that passed our quality assessment criteria. We defined 10 research questions and synthesized different approaches used in primary studies regarding each question.
Results
Majority of studies report the application of crowdsourcing for coding and testing tasks. Crowdsourcing follows a unique methodology in which project planning, task specification and deployment have more emphasis. There is not enough literature on effort estimation approaches in CSE and associated cost factors. Complexity of the task and its expected duration play significant role in estimation.
Conclusions
Future studies should focus more on economic models, experience reports, specific software development methodologies, and strategic pricing mechanism for CSE.}
}
@article{BAKAR2015132,
title = {Feature extraction approaches from natural language requirements for reuse in software product lines: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {106},
pages = {132-149},
year = {2015},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2015.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0164121215001004},
author = {Noor Hasrina Bakar and Zarinah M. Kasirun and Norsaremah Salleh},
keywords = {Feature extractions, Requirements reuse, Software product lines, Natural language requirements, Systematic literature review},
abstract = {Requirements for implemented system can be extracted and reused for a production of a new similar system. Extraction of common and variable features from requirements leverages the benefits of the software product lines engineering (SPLE). Although various approaches have been proposed in feature extractions from natural language (NL) requirements, no related literature review has been published to date for this topic. This paper provides a systematic literature review (SLR) of the state-of-the-art approaches in feature extractions from NL requirements for reuse in SPLE. We have included 13 studies in our synthesis of evidence and the results showed that hybrid natural language processing approaches were found to be in common for overall feature extraction process. A mixture of automated and semi-automated feature clustering approaches from data mining and information retrieval were also used to group common features, with only some approaches coming with support tools. However, most of the support tools proposed in the selected studies were not made available publicly and thus making it hard for practitioners’ adoption. As for the evaluation, this SLR reveals that not all studies employed software metrics as ways to validate experiments and case studies. Finally, the quality assessment conducted confirms that practitioners’ guidelines were absent in the selected studies.}
}
@article{LI20161,
title = {Spot pricing in the Cloud ecosystem: A comparative investigation},
journal = {Journal of Systems and Software},
volume = {114},
pages = {1-19},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2015.10.042},
url = {https://www.sciencedirect.com/science/article/pii/S0164121215002332},
author = {Zheng Li and He Zhang and Liam O’Brien and Shu Jiang and You Zhou and Maria Kihl and Rajiv Ranjan},
keywords = {Cloud computing, Cloud spot pricing, Systematic literature review},
abstract = {Background: Spot pricing is considered as a significant supplement for building a full-fledged market economy for the Cloud ecosystem. However, it seems that both providers and consumers are still hesitating to enter the Cloud spot market. The relevant academic community also has conflicting opinions about Cloud spot pricing in terms of revenue generation. Aim: This work aims to systematically identify, assess, synthesize and report the published evidence in favor of or against spot-price scheme compared with fixed-price scheme of Cloud computing, so as to help relieve the aforementioned conflict. Method: We employed the systematic literature review (SLR) method to collect and investigate the empirical studies of Cloud spot pricing indexed by major electronic libraries. Results: This SLR identified 61 primary studies that either delivered discussions or conducted experiments to perform comparison between spot pricing and fixed pricing in the Cloud domain. The reported benefits and limitations were summarized to facilitate cost-benefit analysis of being a Cloud spot pricing player, while four types of theories were distinguished to help both researchers and practitioners better understand the Cloud spot market. Conclusions: This SLR shows that the academic community strongly advocates the emerging Cloud spot market. Although there is still a lack of practical and easily deployable market-driven mechanisms, the overall findings of our work indicate that spot pricing plays a promising role in the sustainability of Cloud resource exploitation.}
}
@article{SCHEUNER2020110708,
title = {Function-as-a-Service performance evaluation: A multivocal literature review},
journal = {Journal of Systems and Software},
volume = {170},
pages = {110708},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110708},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220301527},
author = {Joel Scheuner and Philipp Leitner},
keywords = {Cloud computing, Serverless, Function-as-a-Service, Performance, Benchmarking, Multivocal literature review},
abstract = {Function-as-a-Service (FaaS) is one form of the serverless cloud computing paradigm and is defined through FaaS platforms (e.g., AWS Lambda) executing event-triggered code snippets (i.e., functions). Many studies that empirically evaluate the performance of such FaaS platforms have started to appear but we are currently lacking a comprehensive understanding of the overall domain. To address this gap, we conducted a multivocal literature review (MLR) covering 112 studies from academic (51) and grey (61) literature. We find that existing work mainly studies the AWS Lambda platform and focuses on micro-benchmarks using simple functions to measure CPU speed and FaaS platform overhead (i.e., container cold starts). Further, we discover a mismatch between academic and industrial sources on tested platform configurations, find that function triggers remain insufficiently studied, and identify HTTP API gateways and cloud storages as the most used external service integrations. Following existing guidelines on experimentation in cloud systems, we discover many flaws threatening the reproducibility of experiments presented in the surveyed studies. We conclude with a discussion of gaps in literature and highlight methodological suggestions that may serve to improve future FaaS performance evaluation studies.}
}
@article{DOGAN2014174,
title = {Web application testing: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {91},
pages = {174-201},
year = {2014},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2014.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0164121214000223},
author = {Serdar Doğan and Aysu Betin-Can and Vahid Garousi},
keywords = {Systematic literature review, Web application, Testing},
abstract = {Context
The web has had a significant impact on all aspects of our society. As our society relies more and more on the web, the dependability of web applications has become increasingly important. To make these applications more dependable, for the past decade researchers have proposed various techniques for testing web-based software applications. Our literature search for related studies retrieved 193 papers in the area of web application testing, which have appeared between 2000 and 2013.
Objective
As this research area matures and the number of related papers increases, it is important to systematically identify, analyze, and classify the publications and provide an overview of the trends and empirical evidence in this specialized field.
Methods
We systematically review the body of knowledge related to functional testing of web application through a systematic literature review (SLR) study. This SLR is a follow-up and complimentary study to a recent systematic mapping (SM) study that we conducted in this area. As part of this study, we pose three sets of research questions, define selection and exclusion criteria, and synthesize the empirical evidence in this area.
Results
Our pool of studies includes a set of 95 papers (from the 193 retrieved papers) published in the area of web application testing between 2000 and 2013. The data extracted during our SLR study is available through a publicly-accessible online repository. Among our results are the followings: (1) the list of test tools in this area and their capabilities, (2) the types of test models and fault models proposed in this domain, (3) the way the empirical studies in this area have been designed and reported, and (4) the state of empirical evidence and industrial relevance.
Conclusion
We discuss the emerging trends in web application testing, and discuss the implications for researchers and practitioners in this area. The results of our SLR can help researchers to obtain an overview of existing web application testing approaches, fault models, tools, metrics and empirical evidence, and subsequently identify areas in the field that require more attention from the research community.}
}
@article{GASPARIC2016101,
title = {What recommendation systems for software engineering recommend: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {113},
pages = {101-113},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2015.11.036},
url = {https://www.sciencedirect.com/science/article/pii/S0164121215002605},
author = {Marko Gasparic and Andrea Janes},
keywords = {Recommendation system for software engineering, Systematic literature review},
abstract = {A recommendation system for software engineering (RSSE) is a software application that provides information items estimated to be valuable for a software engineering task in a given context. Present the results of a systematic literature review to reveal the typical functionality offered by existing RSSEs, research gaps, and possible research directions. We evaluated 46 papers studying the benefits, the data requirements, the information and recommendation types, and the effort requirements of RSSE systems. We include papers describing tools that support source code related development published between 2003 and 2013. The results show that RSSEs typically visualize source code artifacts. They aim to improve system quality, make the development process more efficient and less expensive, lower developer’s cognitive load, and help developers to make better decisions. They mainly support reuse actions and debugging, implementation, and maintenance phases. The majority of the systems are reactive. Unexploited opportunities lie in the development of recommender systems outside the source code domain. Furthermore, current RSSE systems use very limited context information and rely on simple models. Context-adapted and proactive behavior could improve the acceptance of RSSE systems in practice.}
}
@article{MELO2022111483,
title = {Identification and measurement of Requirements Technical Debt in software development: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {194},
pages = {111483},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111483},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222001650},
author = {Ana Melo and Roberta Fagundes and Valentina Lenarduzzi and Wylliams Barbosa Santos},
keywords = {Technical debt, Requirements Technical Debt, Identification, Measurement, Systematic literature review},
abstract = {Context:
Requirements Technical Debt are related to the distance between the ideal value of the specification and the actual implementation of the system, which are consequences of strategic decisions for immediate gains, or unintended changes in context. To ensure the evolution of the software, it is necessary to to manage TD. Identification and measurement are the first two stages of the management process; however, they are poorly explored in academic research in requirements engineering.
Objective:
We aimed to investigating which evidence helps to strengthen the TD requirements management process, including identification and measurement.
Method:
We conducted a Systematic Literature Review through manual and automatic searches considering 7499 studies from 2010 to 2020, and including 66 primary studies.
Results:
We identified some causes related to Technical Debt requirements, existing strategies to help in the identification and measurement, and metrics to support the measurement stage.
Conclusion:
The studies on Requirements Technical Debt are still preliminary, especially regarding management software. Yet, however, the interpersonal aspects that prove difficult in the implementation of such activities are not sufficiently addressed. Finally, the provision of metrics to help measure technical debt is part of the contribution of this search, providing insights into the application in its requirements context.}
}
@article{TUMA2018275,
title = {Threat analysis of software systems: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {144},
pages = {275-294},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.06.073},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218301304},
author = {K. Tuma and G. Calikli and R. Scandariato},
keywords = {Threat analysis (modeling), Risk assessment, Security-by-design, Software systems, Systematic literature review (SLR)},
abstract = {Architectural threat analysis has become an important cornerstone for organizations concerned with developing secure software. Due to the large number of existing techniques it is becoming more challenging for practitioners to select an appropriate threat analysis technique. Therefore, we conducted a systematic literature review (SLR) of the existing techniques for threat analysis. In our study we compare 26 methodologies for what concerns their applicability, characteristics of the required input for analysis, characteristics of analysis procedure, characteristics of analysis outcomes and ease of adoption. We also provide insight into the obstacles for adopting the existing approaches and discuss the current state of their adoption in software engineering trends (e.g. Agile, DevOps, etc.). As a summary of our findings we have observed that: the analysis procedure is not precisely defined, there is a lack of quality assurance of analysis outcomes and tool support and validation are limited.}
}
@article{EDISON2020110520,
title = {Inner source software development: Current thinking and an agenda for future research},
journal = {Journal of Systems and Software},
volume = {163},
pages = {110520},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110520},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220300030},
author = {Henry Edison and Noel Carroll and Lorraine Morgan and Kieran Conboy},
keywords = {Inner source, Inner source software development, Research agenda, Systematic literature review},
abstract = {Context
Inner source software development (ISSD) has been viewed as an alternative approach in which organisations adopt open source software development (OSSD) practices and exploit its benefits internally.
Objective
In this paper, we aim to provide an extensive review of current research on ISSD and to establish a research agenda on this domain.
Method
The review is primarily performed using a systematic literature review protocol.
Results
We identified, critically evaluated and integrated the findings of 37 primary studies, describing 25 empirical research papers, 10 frameworks/methods, models and tools to support the implementation of inner source, as well as a set of benefits and challenges associated with ISSD.
Conclusion
This study presents four main contributions. First, the study provides an in-depth review of ISSD to date, i.e. the evolution of research across inner source, contributions of existing research developments, and theories, models and frameworks used to study inner source. Second, our review applies the OSSD approach framework as the lens to analyse ISSD. Third, the review updates the key challenges associated with ISSD from a management perspective. The final contribution is the establishment of a research agenda to advance knowledge on ISSD.}
}
@article{RAATIKAINEN2019485,
title = {Software product lines and variability modeling: A tertiary study},
journal = {Journal of Systems and Software},
volume = {149},
pages = {485-510},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.12.027},
url = {https://www.sciencedirect.com/science/article/pii/S016412121830284X},
author = {Mikko Raatikainen and Juha Tiihonen and Tomi Männistö},
keywords = {Software product line, Variability, Variability modeling, Systematic literature review, Mapping study, Tertiary study},
abstract = {Context: A software product line is a means to develop a set of products in which variability is a central phenomenon captured in variability models. The field of SPLs and variability have been topics of extensive research over the few past decades. Objective: This research characterizes systematic reviews (SRs) in the field, studies how SRs analyze and use evidence-based results, and identifies how variability is modeled. Method: We conducted a tertiary study as a form of systematic review. Results: 86 SRs were included. SRs have become a widely adopted methodology covering the field broadly otherwise except for variability realization. Numerous variability models exist that cover different development artifacts, but the evidence is insufficient in quantity and immature, and we argue for better evidence. SRs perform well in searching and selecting studies and presenting data. However, their analysis and use of the quality of and evidence in the primary studies often remains shallow, merely presenting of what kinds of evidence exist. Conclusions: There is a need for actionable, context-sensitive, and evaluated solutions rather than novel ones. Different kinds of SRs (SLRs and Maps) need to be better distinguished, and evidence and quality need to be better used in the resulting syntheses.}
}
@article{VILELA201768,
title = {Integration between requirements engineering and safety analysis: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {125},
pages = {68-92},
year = {2017},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.11.031},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216302333},
author = {Jéssyka Vilela and Jaelson Castro and Luiz Eduardo G. Martins and Tony Gorschek},
keywords = {Safety-critical systems, Requirements engineering, Safety analysis, Integration, Communication, Systematic literature review},
abstract = {Context: Safety-Critical Systems (SCS) require more sophisticated requirements engineering (RE) approaches as inadequate, incomplete or misunderstood requirements have been recognized as a major cause in many accidents and safety-related catastrophes. Objective: In order to cope with the complexity of specifying SCS by RE, we investigate the approaches proposed to improve the communication or integration between RE and safety engineering in SCS development. We analyze the activities that should be performed by RE during safety analysis, the hazard/safety techniques it could use, the relationships between safety information that it should specify, the tools to support safety analysis as well as integration benefits between these areas. Method: We use a Systematic Literature Review (SLR) as the basis for our work. Results: We developed four taxonomies to help RE during specification of SCS that classify: techniques used in (1) hazard analysis; (2) safety analysis; (3) safety-related information and (4) a detailed set of information regarding hazards specification. Conclusions: This paper is a step towards developing a body of knowledge in safety concerns necessary to RE in the specification of SCS that is derived from a large-scale SLR. We believe the results will benefit both researchers and practitioners.}
}
@article{SOUALHIA2017170,
title = {Task Scheduling in Big Data Platforms: A Systematic Literature Review},
journal = {Journal of Systems and Software},
volume = {134},
pages = {170-189},
year = {2017},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2017.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0164121217301954},
author = {Mbarka Soualhia and Foutse Khomh and Sofiène Tahar},
keywords = {Task Scheduling, Hadoop, Spark, Storm, Mesos, Systematic Literature Review},
abstract = {Context: Hadoop, Spark, Storm, and Mesos are very well known frameworks in both research and industrial communities that allow expressing and processing distributed computations on massive amounts of data. Multiple scheduling algorithms have been proposed to ensure that short interactive jobs, large batch jobs, and guaranteed-capacity production jobs running on these frameworks can deliver results quickly while maintaining a high throughput. However, only a few works have examined the effectiveness of these algorithms. Objective: The Evidence-based Software Engineering (EBSE) paradigm and its core tool, i.e., the Systematic Literature Review (SLR), have been introduced to the Software Engineering community in 2004 to help researchers systematically and objectively gather and aggregate research evidences about different topics. In this paper, we conduct a SLR of task scheduling algorithms that have been proposed for big data platforms. Method: We analyse the design decisions of different scheduling models proposed in the literature for Hadoop, Spark, Storm, and Mesos over the period between 2005 and 2016. We provide a research taxonomy for succinct classification of these scheduling models. We also compare the algorithms in terms of performance, resources utilization, and failure recovery mechanisms. Results: Our searches identifies 586 studies from journals, conferences and workshops having the highest quality in this field. This SLR reports about different types of scheduling models (dynamic, constrained, and adaptive) and the main motivations behind them (including data locality, workload balancing, resources utilization, and energy efficiency). A discussion of some open issues and future challenges pertaining to improving the current studies is provided.}
}
@article{LANO201848,
title = {A survey of model transformation design patterns in practice},
journal = {Journal of Systems and Software},
volume = {140},
pages = {48-73},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218300438},
author = {Kevin Lano and Shekoufeh Kolahdouz-Rahimi and Sobhan Yassipour-Tehrani and Mohammadreza Sharbaf},
keywords = {Model Transformations, Design Patterns, Empirical Software Engineering},
abstract = {Model transformation design patterns have been proposed by a number of researchers, but their usage appears to be sporadic and sometimes patterns are applied without recognition of the pattern. In this paper we provide a systematic literature review of transformation design pattern applications. We evaluate how widely patterns have been used, and how their use differs in different transformation languages and for different categories of transformation. We identify what benefits appear to arise from the use of patterns, and consider how the application of patterns can be improved. The paper also identifies several new patterns which have not previously been catalogued.}
}
@article{FELIZARDO2020110734,
title = {Secondary studies in the academic context: A systematic mapping and survey},
journal = {Journal of Systems and Software},
volume = {170},
pages = {110734},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110734},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220301655},
author = {Katia Romero Felizardo and Érica Ferreira {de Souza} and Bianca Minetto Napoleão and Nandamudi Lankalapalli Vijaykumar and Maria Teresa Baldassarre},
keywords = {Education, Secondary studies, Systematic literature review, Systematic mapping},
abstract = {Context:
Several researchers have reported their experiences in applying secondary studies (Systematic Literature Reviews — SLRs and Systematic Mappings — SMs) in Software Engineering (SE). However, there is still a lack of studies discussing the value of performing secondary studies in an academic context.
Goal:
The main goal of this study is to provide an overview on the use of secondary studies in an academic context.
Method:
Two empirical research methods were used. Initially, we conducted a SM to identify the available and relevant studies on the use of secondary studies as a research methodology for conducting SE research projects. Secondly, a survey was performed with 64 SE researchers to identify their perception related to the value of performing secondary studies to support their research projects.
Results:
Our results show benefits of using secondary studies in the academic context, such as providing an overview of the literature as well as identifying relevant research literature on a research area enabling to find reasons to explain why a research project should be approved for a grant and/or supporting decisions made in a research project. Difficulties faced by SE graduate students with secondary studies are that they tend to be conducted by a team and it demands more effort than a traditional review.
Conclusions:
Secondary studies are valuable to graduate students. They should consider conducting a secondary study for their research project due to the benefits and contributions provided to develop the overall project. However, the advice of an experienced supervisor is essential to avoid bias. In addition, the acquisition of skills can increase student’s motivation to pursue their research projects and prepare them for both academic or industrial careers.}
}
@article{BESKER20181,
title = {Managing architectural technical debt: A unified model and systematic literature review},
journal = {Journal of Systems and Software},
volume = {135},
pages = {1-16},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2017.09.025},
url = {https://www.sciencedirect.com/science/article/pii/S0164121217302121},
author = {Terese Besker and Antonio Martini and Jan Bosch},
keywords = {Systematic literature review, Architectural technical debt, Software maintenance, Software architecture},
abstract = {Large Software Companies need to support the continuous and fast delivery of customer value in both the short and long term. However, this can be impeded if the evolution and maintenance of existing systems is hampered by what has been recently termed Technical Debt (TD). Specifically, Architectural TD has received increased attention in the last few years due to its significant impact on system success and, left unchecked, it can cause expensive repercussions. It is therefore important to understand the underlying factors of architectural TD. With this as background, there is a need for a descriptive model to illustrate and explain different architectural TD issues. The aim of this study is to synthesize and compile research efforts with the goal of creating new knowledge with a specific interest in the architectural TD field. The contribution of this paper is the presentation of a novel descriptive model, providing a comprehensive interpretation of the architectural TD phenomenon. This model categorizes the main characteristics of architectural TD and reveals their relations. The results show that, by using this model, different stakeholders could increase the system's success rate, and lower the rate of negative consequences, by raising awareness about architectural TD.}
}
@article{MANIKAS20131294,
title = {Software ecosystems – A systematic literature review},
journal = {Journal of Systems and Software},
volume = {86},
number = {5},
pages = {1294-1306},
year = {2013},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2012.12.026},
url = {https://www.sciencedirect.com/science/article/pii/S016412121200338X},
author = {Konstantinos Manikas and Klaus Marius Hansen},
keywords = {Software ecosystems, Software ecosystem, Systematic literature review},
abstract = {A software ecosystem is the interaction of a set of actors on top of a common technological platform that results in a number of software solutions or services. Arguably, software ecosystems are gaining importance with the advent of, e.g., the Google Android, Apache, and Salesforce.com ecosystems. However, there exists no systematic overview of the research done on software ecosystems from a software engineering perspective. We performed a systematic literature review of software ecosystem research, analyzing 90 papers on the subject taken from a gross collection of 420. Our main conclusions are that while research on software ecosystems is increasing (a) there is little consensus on what constitutes a software ecosystem, (b) few analytical models of software ecosystems exist, and (c) little research is done in the context of real-world ecosystems. This work provides an overview of the field, while identifying areas for future research.}
}
@article{SANCHEZGUINEA2016251,
title = {A systematic review on the engineering of software for ubiquitous systems},
journal = {Journal of Systems and Software},
volume = {118},
pages = {251-276},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.05.024},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216300553},
author = {Alejandro {Sánchez Guinea} and Grégory Nain and Yves {Le Traon}},
keywords = {Empirical software engineering, Evidence-based software engineering, Systematic review, Research synthesis, Software development cycle, Ubiquitous systems, Development methods, Pervasive systems},
abstract = {Context: Software engineering for ubiquitous systems has experienced an important and rapid growth, however the vast research corpus makes it difficult to obtain valuable information from it. Objective: To identify, evaluate, and synthesize research about the most relevant approaches addressing the different phases of the software development life cycle for ubiquitous systems. Method: We conducted a systematic literature review of papers presenting and evaluating approaches for the different phases of the software development life cycle for ubiquitous systems. Approaches were classified according to the phase of the development cycle they addressed, identifying their main concerns and limitations. Results: We identified 128 papers reporting 132 approaches addressing issues related to different phases of the software development cycle for ubiquitous systems. Most approaches have been aimed at addressing the implementation, evolution/maintenance, and feedback phases, while others phases such as testing need more attention from researchers. Conclusion: We recommend to follow existing guidelines when conducting case studies to make the studies more reproducible and closer to real life cases. While some phases of the development cycle have been extensively explored, there is still room for research in other phases, toward a more agile and integrated cycle, from requirements to testing and feedback.}
}
@article{HOFER2021110910,
title = {Product metrics for spreadsheets—A systematic review},
journal = {Journal of Systems and Software},
volume = {175},
pages = {110910},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.110910},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221000078},
author = {Birgit Hofer and Dietmar Jannach and Patrick Koch and Konstantin Schekotihin and Franz Wotawa},
keywords = {Spreadsheet quality assurance, Spreadsheet metrics, Metrics catalog, Spreadsheet product metrics, Spreadsheet metrics survey},
abstract = {Software product metrics allow practitioners to improve their products and to optimize development processes based on quantifiable characteristics of source code. To facilitate similar benefits for spreadsheet programs, researchers proposed various product metrics for spreadsheets over the last decades. However, to our knowledge, no comprehensive overview of those efforts is currently available. In this paper, we close this gap by conducting a literature review of research works that either inherently or explicitly define product metrics for spreadsheets. We scanned five major digital libraries for scientific papers that define or use spreadsheet product metrics. Based on the identified 37 papers, we created a novel catalog of product metrics for spreadsheets. The catalog can be used by practitioners and researchers as a central reference for spreadsheet product metrics. In the paper, we (i) describe the proposed metrics in detail, (ii) report how often and for what purposes the metrics are used, (iii) identify significant discrepancies in the naming and definition of the metrics, and (iv) investigate how the appropriateness of the metrics was evaluated.}
}
@article{DECKERS2022111415,
title = {Systematic literature review of domain-oriented specification techniques},
journal = {Journal of Systems and Software},
volume = {192},
pages = {111415},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111415},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222001261},
author = {Robert Deckers and Patricia Lago},
keywords = {Domain-specific language, Domain model, Systematic literature review, Method comparison, Specification method, Modeling language},
abstract = {Context:
The popularity of domain-specific languages and model driven development has made the tacit use of domain knowledge in system development more tangible. Our vision is a development process where a (software) system specification is based on multiple domain models, and where the specification method is built from cognitive concepts, presumably derived from natural language.
Goal:
To realize this vision, we evaluate and reflect upon the existing literature in domain-oriented specification techniques.
Method:
We designed and conducted a systematic literature review on domain-oriented specification techniques.
Results:
We identified 53 primary studies, populated the classification framework for each study, and summarized our findings per classification aspect. We found many approaches for creating domain models or domain-specific languages. Observations include: (i) most methods are defined incompletely; (ii) none offers methodical support for the use of domain models or domain-specific languages to create other specifications; (iii) there are specification techniques to integrate models in general, but no study offers methodical support for multiple domain models.
Conclusion:
The results indicate which topics need further research and which can instead be reused to realize our vision on system development. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.}
}
@article{SOBERNIG2016140,
title = {Extracting reusable design decisions for UML-based domain-specific languages: A multi-method study},
journal = {Journal of Systems and Software},
volume = {113},
pages = {140-172},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2015.11.037},
url = {https://www.sciencedirect.com/science/article/pii/S0164121215002617},
author = {Stefan Sobernig and Bernhard Hoisl and Mark Strembeck},
keywords = {Domain-specific language, Unified modeling language, Design decision, Design rationale, Domain-specific modeling, Model-driven development},
abstract = {When developing domain-specific modeling languages (DSMLs), software engineers have to make a number of important design decisions on the DSML itself, or on the software-development process that is applied to develop the DSML. Thus, making well-informed design decisions is a critical factor in developing DSMLs. To support this decision-making process, the model-driven development community has started to collect established design practices in terms of patterns, guidelines, story-telling, and procedural models. However, most of these documentation practices do not capture the details necessary to reuse the rationale behind these decisions in other DSML projects. In this paper, we report on a three-year research effort to compile and to empirically validate a catalog of structured decision descriptions (decision records) for UML-based DSMLs. This catalog is based on design decisions extracted from 90 DSML projects. These projects were identified—among others—via an extensive systematic literature review (SLR) for the years 2005–2012. Based on more than 8,000 candidate publications, we finally selected 84 publications for extracting design-decision data. The extracted data were evaluated quantitatively using a frequent-item-set analysis to obtain characteristic combinations of design decisions and qualitatively to document recurring documentation issues for UML-based DSMLs. We revised the collected decision records based on this evidence and made the decision-record catalog for developing UML-based DSMLs publicly available. Furthermore, our study offers insights into UML usage (e.g. diagram types) and into the adoption of UML extension techniques (e.g. metamodel extensions, profiles).}
}
@article{DIKERT201687,
title = {Challenges and success factors for large-scale agile transformations: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {119},
pages = {87-108},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.06.013},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216300826},
author = {Kim Dikert and Maria Paasivaara and Casper Lassenius},
keywords = {Agile software development, Organizational transformation, Large-scale agile, Adopting agile software development, Challenges, Success factors, Systematic literature review},
abstract = {Agile methods have become an appealing alternative for companies striving to improve their performance, but the methods were originally designed for small and individual teams. This creates unique challenges when introducing agile at scale, when development teams must synchronize their activities, and there might be a need to interface with other organizational units. In this paper we present a systematic literature review on how agile methods and lean software development has been adopted at scale, focusing on reported challenges and success factors in the transformation. We conducted a systematic literature review of industrial large-scale agile transformations. Our keyword search found 1875 papers. We included 52 publications describing 42 industrial cases presenting the process of taking large-scale agile development into use. Almost 90% of the included papers were experience reports, indicating a lack of sound academic research on the topic. We identified 35 reported challenges grouped into nine categories, and 29 success factors, grouped into eleven categories. The most salient success factor categories were management support, choosing and customizing the agile model, training and coaching, and mindset and alignment.}
}
@article{GENCNAYEBI2017207,
title = {A systematic literature review: Opinion mining studies from mobile app store user reviews},
journal = {Journal of Systems and Software},
volume = {125},
pages = {207-219},
year = {2017},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.11.027},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216302291},
author = {Necmiye Genc-Nayebi and Alain Abran},
keywords = {Mobile application, App stores opinion mining, Systematic literature review, Requirements engineering},
abstract = {As mobile devices have overtaken fixed Internet access, mobile applications and distribution platforms have gained in importance. App stores enable users to search for, purchase and install mobile applications and then give feedback in the form of reviews and ratings. A review might contain information about the user’s experience with the app and opinion of it, feature requests and bug reports. Hence, reviews are valuable not only to users who would like to find out what others think about an app, but also to developers and software companies interested in customer feedback. The rapid increase in the number of applications and total app store revenue has accelerated app store data mining and opinion aggregation studies. While development companies and app store regulators have pursued upfront opinion mining studies for business intelligence and marketing purposes, research interest into app ecosystem and user reviews is relatively new. In addition to studies examining online product reviews, there are now some academic studies focused on mobile app stores and user reviews. The objectives of this systematic literature review are to identify proposed solutions for mining online opinions in app store user reviews, challenges and unsolved problems in the domain, any new contributions to software requirements evolution and future research direction.}
}
@article{HIRSCH2022111423,
title = {A systematic literature review on benchmarks for evaluating debugging approaches},
journal = {Journal of Systems and Software},
volume = {192},
pages = {111423},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111423},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222001303},
author = {Thomas Hirsch and Birgit Hofer},
keywords = {Debugging, Benchmark, Fault localization, Automatic repair},
abstract = {Bug benchmarks are used in development and evaluation of debugging approaches, e.g. fault localization and automated repair. Quantitative performance comparison of different debugging approaches is only possible when they have been evaluated on the same dataset or benchmark. However, benchmarks are often specialized towards usage for certain debugging approaches in their contained data, metrics, and artifacts. Such benchmarks cannot be easily used on debugging approaches outside their scope as such approach may rely on specific data such as bug reports or code metrics that are not included in the dataset. Furthermore, benchmarks vary in their size w.r.t. the number of subject programs and the size of the individual subject programs. For these reasons, we have performed a systematic literature review where we have identified 73 benchmarks that can be used to evaluate debugging approaches. We compare the different benchmarks w.r.t. their size and the provided information such as bug reports, contained test cases, and other code metrics. This comparison is intended to help researchers to quickly identify all suitable benchmarks for evaluating their specific debugging approaches. Furthermore, we discuss reoccurring issues and challenges in selection, acquisition, and usage of such bug benchmarks, i.e., data availability, data quality, duplicated content, data formats, reproducibility, and extensibility. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.}
}
@article{WOHLIN20132594,
title = {On the reliability of mapping studies in software engineering},
journal = {Journal of Systems and Software},
volume = {86},
number = {10},
pages = {2594-2610},
year = {2013},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2013.04.076},
url = {https://www.sciencedirect.com/science/article/pii/S0164121213001234},
author = {Claes Wohlin and Per Runeson and Paulo Anselmo {da Mota Silveira Neto} and Emelie Engström and Ivan {do Carmo Machado} and Eduardo Santana {de Almeida}},
keywords = {Systematic mapping study, Software product lines, Systematic literature review, Review of reviews, Software testing},
abstract = {Background
Systematic literature reviews and systematic mapping studies are becoming increasingly common in software engineering, and hence it becomes even more important to better understand the reliability of such studies.
Objective
This paper presents a study of two systematic mapping studies to evaluate the reliability of mapping studies and point out some challenges related to this type of study in software engineering.
Method
The research is based on an in-depth case study of two published mapping studies on software product line testing.
Results
We found that despite the fact that the two studies are addressing the same topic, there are quite a number of differences when it comes to papers included and in terms of classification of the papers included in the two mapping studies.
Conclusions
From this we conclude that although mapping studies are important, their reliability cannot simply be taken for granted. Based on the findings we also provide four conjectures that further research has to address to make secondary studies (systematic mapping studies and systematic literature reviews) even more valuable to both researchers and practitioners.}
}
@article{ABDELLATIF2021110868,
title = {A taxonomy of service identification approaches for legacy software systems modernization},
journal = {Journal of Systems and Software},
volume = {173},
pages = {110868},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110868},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220302582},
author = {Manel Abdellatif and Anas Shatnawi and Hafedh Mili and Naouel Moha and Ghizlane El Boussaidi and Geoffrey Hecht and Jean Privat and Yann-Gaël Guéhéneuc},
keywords = {Service identification, Microservices, Taxonomy, Legacy system, Migration},
abstract = {The success of modernizing legacy software systems to Service-Oriented Architecture (SOA) depends on Service Identification Approaches (SIAs), which identify reusable functionalities that could become services. The literature describes several SIAs. However, the selection of an identification approach that is suitable for a practitioner is difficult because it depends on several factors, including the goal of modernization, the available legacy artifacts, the organization’s development process, the desired output, and the usability of the approach. Accordingly, to select a suitable service identification approach, a practitioner must have a comprehensive view of existing techniques. We report a systematic literature review (SLR) that covers 41 SIAs based on software-systems analyses. Based on this SLR, we create a taxonomy of SIAs and build a multi-layer classification of existing identification approaches. We start from a high-level classification based on the used inputs, the applied processes, the given outputs, and the usability of the SIAs. We then divide each category into a fine-grained taxonomy that helps practitioners in selecting a suitable approach for identifying services in legacy software systems. We build our SLR based on our experience with legacy software modernization, on discussions and experiences working with industrial partners, and analyses of existing SIAs. We validate the correctness and the coverage of our review with industrial experts who modernize(d) legacy software systems to SOA. The results show that our classification conforms to the industrial experts’ experiences. We also show that most of the studied SIAs are still at their infancy. Finally, we identify the main challenges that SIAs need to address, to improve their quality.}
}
@article{REZENDE201943,
title = {Software project scheduling problem in the context of search-based software engineering: A systematic review},
journal = {Journal of Systems and Software},
volume = {155},
pages = {43-56},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.05.024},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219301086},
author = {Allan Vinicius Rezende and Leila Silva and André Britto and Rodrigo Amaral},
keywords = {Search-based software engineering, Software project scheduling problem, Systematic review},
abstract = {This work provides a systematic literature review of the software project scheduling problem, in the context of search-based software engineering, and summarizes the main models, techniques, search algorithms and evaluation criteria applied to solve this problem. We also discuss trends and research opportunities. Our keyword search found 438 papers, published in the last 20 years. After considering the inclusion and exclusion criteria and performing the snowballing procedure, we have analyzed 37 primary studies. The results show the predominance of the use of evolutionary algorithms. The static model, in which the scheduling is performed once during the project, is considered in the majority of the papers. Synthetic instances are commonly used to validate the heuristic and hypervolume and execution time are the mostly applied evaluating criteria.}
}
@article{LO2022111357,
title = {Architectural patterns for the design of federated learning systems},
journal = {Journal of Systems and Software},
volume = {191},
pages = {111357},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111357},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222000899},
author = {Sin Kit Lo and Qinghua Lu and Liming Zhu and Hye-Young Paik and Xiwei Xu and Chen Wang},
keywords = {Federated learning, Pattern, Software architecture, Machine learning, Artificial intelligence},
abstract = {Federated learning has received fast-growing interests from academia and industry to tackle the challenges of data hungriness and privacy in machine learning. A federated learning system can be viewed as a large-scale distributed system with different components and stakeholders as numerous client devices participate in federated learning. Designing a federated learning system requires software system design thinking apart from the machine learning knowledge. Although much effort has been put into federated learning from the machine learning technique aspects, the software architecture design concerns in building federated learning systems have been largely ignored. Therefore, in this paper, we present a collection of architectural patterns to deal with the design challenges of federated learning systems. Architectural patterns present reusable solutions to a commonly occurring problem within a given context during software architecture design. The presented patterns are based on the results of a systematic literature review and include three client management patterns, four model management patterns, three model training patterns, four model aggregation patterns, and one configuration pattern. The patterns are associated to the particular state transitions in a federated learning model lifecycle, serving as a guidance for effective use of the patterns in the design of federated learning systems.}
}
@article{ALI2016402,
title = {Software outsourcing partnership model: An evaluation framework for vendor organizations},
journal = {Journal of Systems and Software},
volume = {117},
pages = {402-425},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.03.069},
url = {https://www.sciencedirect.com/science/article/pii/S016412121630019X},
author = {Sikandar Ali and Siffat Ullah Khan},
keywords = {Software outsourcing partnership, Systematic literature review, Critical success factors},
abstract = {Software Outsourcing Partnership (SOP) is a new software development paradigm for developing high quality software products. A SOP is different to ordinary software development outsourcing (SDO) relationship. SOP is the enhanced form of conventional outsourcing relationship. The objective of this research paper is to develop a software outsourcing partnership model (SOPM) to identify and analyze factors that are important for vendors in conversion of their existing outsourcing relationship to partnership. We have performed a systematic literature review (SLR) process for the identification of critical success factors (CSFs) from a sample of 111 articles. Further we have categorized the identified CSFs into five partnership levels based on Capability Maturity Model Integration (CMMI) and Software Outsourcing Vendors’ Readiness Model (SOVRM). To validate the SLR findings and to find practices for the identified CSFs a questionnaire survey was conducted in the outsourcing industry in which 35 experts, from 8 different countries participated. Two case studies were conducted for evaluation of the SOPM. In this paper our newly developed model, SOPM, has been presented in detail. SOPM has been built with the intent to assist SDO vendor organizations in measuring their capabilities for successful conversion of their contractual outsourcing relationship to outsourcing partnership.}
}
@article{LEI2022111141,
title = {Deep learning application on code clone detection: A review of current knowledge},
journal = {Journal of Systems and Software},
volume = {184},
pages = {111141},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111141},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221002387},
author = {Maggie Lei and Hao Li and Ji Li and Namrata Aundhkar and Dae-Kyoo Kim},
keywords = {Code clone, Code smell, Deep learning, Duplicate code, Machine learning, Literature review},
abstract = {Bad smells in code are indications of low code quality representing potential threats to the maintainability and reusability of software. Code clone is a type of bad smells caused by code fragments that have the same functional semantics with syntactic variations. In the recent years, the research on duplicate code has been dramatically geared up by deep learning techniques powered by advances in computing power. However, there exists little work studying the current state-of-art and future prospects in the area of applying deep learning to code clone detection. In this paper, we present a systematic review of the literature on the application of deep learning on code clone detection. We aim to find and study the most recent work on the subject, discuss their limitations and challenges, and provide insights on the future work.}
}
@article{KAUR2017152,
title = {Software component and the semantic Web: An in-depth content analysis and integration history},
journal = {Journal of Systems and Software},
volume = {125},
pages = {152-169},
year = {2017},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.11.028},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216302308},
author = {Loveleen Kaur and Ashutosh Mishra},
keywords = {Component-based software engineering, Semantic Web, Ontology, Reasoners, Web services, Linked Data},
abstract = {With the advent of Component-based software engineering (CBSE), large software systems are being built by integrating pre-built software components. The Semantic Web in association with CBSE has shown to offer powerful representation facilities and reasoning techniques to enhance and support querying, reasoning, discovery, etc. of software components. The goal of this paper is to research the applicability of Semantic Web technologies in performing the various tasks of CBSE and review the experimental results of the same in an easy and effective manner. To the best of our knowledge, this is the first study which provides an extensive review of the application of Semantic Web in CBSE from different perspectives. A systematic literature review of the Semantic Web approaches, employed for use in CBSE, reported from 2001 until 2015, is conducted in this research article. Empirical results have been drawn through the question-answer based analysis of the research, which clearly tells the year wise trend of the research articles, with the possible justification of the usage of Semantic Web technology and tools for a particular phase of CBSE. To conclude, gaps in the current research and potential future prospects have been discussed.}
}
@article{GIRAY2021111031,
title = {A software engineering perspective on engineering machine learning systems: State of the art and challenges},
journal = {Journal of Systems and Software},
volume = {180},
pages = {111031},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111031},
url = {https://www.sciencedirect.com/science/article/pii/S016412122100128X},
author = {Görkem Giray},
keywords = {Software engineering, Software development, Software process, Machine learning, Deep learning, Systematic literature review},
abstract = {Context:
Advancements in machine learning (ML) lead to a shift from the traditional view of software development, where algorithms are hard-coded by humans, to ML systems materialized through learning from data. Therefore, we need to revisit our ways of developing software systems and consider the particularities required by these new types of systems.
Objective:
The purpose of this study is to systematically identify, analyze, summarize, and synthesize the current state of software engineering (SE) research for engineering ML systems.
Method:
I performed a systematic literature review (SLR). I systematically selected a pool of 141 studies from SE venues and then conducted a quantitative and qualitative analysis using the data extracted from these studies.
Results:
The non-deterministic nature of ML systems complicates all SE aspects of engineering ML systems. Despite increasing interest from 2018 onwards, the results reveal that none of the SE aspects have a mature set of tools and techniques. Testing is by far the most popular area among researchers. Even for testing ML systems, engineers have only some tool prototypes and solution proposals with weak experimental proof. Many of the challenges of ML systems engineering were identified through surveys and interviews. Researchers should conduct experiments and case studies, ideally in industrial environments, to further understand these challenges and propose solutions.
Conclusion:
The results may benefit (1) practitioners in foreseeing the challenges of ML systems engineering; (2) researchers and academicians in identifying potential research questions; and (3) educators in designing or updating SE courses to cover ML systems engineering.}
}
@article{BADAMPUDI2016105,
title = {Software component decision-making: In-house, OSS, COTS or outsourcing - A systematic literature review},
journal = {Journal of Systems and Software},
volume = {121},
pages = {105-124},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.07.027},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216301212},
author = {Deepika Badampudi and Claes Wohlin and Kai Petersen},
keywords = {OSS, COTS, In-house development, Outsourcing, Decision-making, Component-based software engineering},
abstract = {Context: Component-based software systems require decisions on component origins for acquiring components. A component origin is an alternative of where to get a component from. Objective: To identify factors that could influence the decision to choose among different component origins and solutions for decision-making (For example, optimization) in the literature. Method: A systematic review study of peer-reviewed literature has been conducted. Results: In total we included 24 primary studies. The component origins compared were mainly focused on in-house vs. COTS and COTS vs. OSS. We identified 11 factors affecting or influencing the decision to select a component origin. When component origins were compared, there was little evidence on the relative (either positive or negative) effect of a component origin on the factor. Most of the solutions were proposed for in-house vs. COTS selection and time, cost and reliability were the most considered factors in the solutions. Optimization models were the most commonly proposed technique used in the solutions. Conclusion: The topic of choosing component origins is a green field for research, and in great need of empirical comparisons between the component origins, as well of how to decide between different combinations of them.}
}
@article{DAVILA2021110951,
title = {A systematic literature review and taxonomy of modern code review},
journal = {Journal of Systems and Software},
volume = {177},
pages = {110951},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.110951},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221000480},
author = {Nicole Davila and Ingrid Nunes},
keywords = {Modern code review, Software verification, Software quality, Systematic literature review},
abstract = {Context:
Modern Code Review (MCR) is a widely known practice of software quality assurance. However, the existing body of knowledge of MCR is currently not understood as a whole.
Objective:
Our goal is to identify the state of the art on MCR, providing a structured overview and an in-depth analysis of the research done in this field.
Methods:
We performed a systematic literature review, selecting publications from four digital libraries.
Results:
A total of 139 papers were selected and analyzed in three main categories. Foundational studies are those that analyze existing or collected data from the adoption of MCR. Proposals consist of techniques and tools to support MCR, while evaluations are studies to assess an approach or compare a set of them.
Conclusion:
The most represented category is foundational studies, mainly aiming to understand the motivations for adopting MCR, its challenges and benefits, and which influence factors lead to which MCR outcomes. The most common types of proposals are code reviewer recommender and support to code checking. Evaluations of MCR-supporting approaches have been done mostly offline, without involving human subjects. Five main research gaps have been identified, which point out directions for future work in the area.}
}
@article{SOLDANI2018215,
title = {The pains and gains of microservices: A Systematic grey literature review},
journal = {Journal of Systems and Software},
volume = {146},
pages = {215-232},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.09.082},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218302139},
author = {Jacopo Soldani and Damian Andrew Tamburri and Willem-Jan {Van Den Heuvel}},
keywords = {Microservices, Microservices design, Microservices development, Microservices operation, Systematic grey literature review, Systematic literature review},
abstract = {The design, development, and operation of microservices are picking up more and more momentum in the IT industry. At the same time, academic work on the topic is at an early stage, and still on the way to distilling the actual “Pains & Gains” of microservices as an architectural style. Having witnessed this gap, we set forth to systematically analyze the industrial grey literature on microservices, to identify the technical/operational pains and gains of the microservice-based architectural style. We conclude by discussing research directions stemming out from our analysis.}
}
@article{GEISMANN2020110697,
title = {A systematic literature review of model-driven security engineering for cyber–physical systems},
journal = {Journal of Systems and Software},
volume = {169},
pages = {110697},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110697},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220301461},
author = {Johannes Geismann and Eric Bodden},
keywords = {Literature survey, Systematic literature review, Model-driven security, Cyber–physical systems, Platform-specific, Security modeling},
abstract = {The last years have elevated the importance of cyber–physical systems like IoT applications, smart cars, or industrial control systems, and, therefore, these systems have also come into the focus of attackers. In contrast to software products running on PCs or smartphones, updating and maintaining cyber–physical systems presents a major challenge. This challenge, combined with the often decades-long lifetime of cyber–physical systems, and with their deployment in often safety-critical contexts, makes it particularly important to consider their security already at design time. When aiming to obtain a provably secure design, model-driven security approaches are key, as they allow to identify and mitigate threats in early phases of the development. As attacks may exploit both code-level as well as physical vulnerabilities, such approaches must consider not just the cyber layer but the physical layer as well. To find out which model-driven security approaches for cyber–physical systems exist considering both layers, we conducted a systematic literature review. From a set of 1160 initial papers, we extracted 69 relevant publications describing 17 candidate approaches. We found seven approaches specifically developed for cyber–physical systems. We provide a comprehensive description of these approaches, discuss them in particular detail, and determine their limitations. We found out that model-driven security is a relevant research area but most approaches focus only on specific security properties and even for CPS-specific approaches the platform is only rarely taken into account.}
}
@article{PAIVA2021110819,
title = {Accessibility and Software Engineering Processes: A Systematic Literature Review},
journal = {Journal of Systems and Software},
volume = {171},
pages = {110819},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110819},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220302168},
author = {Débora Maria Barroso Paiva and André Pimenta Freire and Renata Pontin {de Mattos Fortes}},
keywords = {Accessibility, Software Engineering, Systematic Literature Review, Design for disabilities, Methods for accessibility},
abstract = {Guidelines, techniques, and methods have been presented in the literature in recent years to contribute to the development of accessible software and to promote digital inclusion. Considering that software product quality depends on the quality of the development process, researchers have investigated how to include accessibility during the software development process in order to obtain accessible software. Two Systematic Literature Reviews (SLR) have been conducted in the past to identify such research initiatives. This paper presents a new SLR, considering the period from 2011 to 2019. The review of 94 primary studies showed the distribution of publications on different phases of the software life cycle, mainly the design and testing phases. The study also identified, for the first time, papers about accessibility and software process establishment. This result reinforces that, in fact, accessibility is not characterized as a property of the final software only. Instead, it evolves over the software life cycle. Besides, this study aims to provide designers and developers with an updated view of methods, tools, and other assets that contribute to process enrichment, valuing accessibility, as well as shows the gaps and challenges which deserve to be investigated.}
}
@article{MARCHEZAN2022111189,
title = {Software product line scoping: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {186},
pages = {111189},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111189},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221002673},
author = {Luciano Marchezan and Elder Rodrigues and Wesley Klewerton Guez Assunção and Maicon Bernardino and Fábio Paulo Basso and João Carbonell},
keywords = {Software product lines, Software product line scoping, Systematic literature review, Snowballing},
abstract = {Software product line (SPL) scoping aids companies to define the boundaries of their resources such as products, domains, and assets, the target of reuse tasks scoping technical and organizational aspects. As scoping guides the management of the resources in SPL development, it becomes one of the core activities in this process. We can find in the literature several approaches on this topic, proposing techniques and methodologies to be applicable in different organizational scenarios. However, no work comprehensively reviews such approaches and describes the advances in state of the art in the last years. In this context, we look into identifying, analyzing, and extracting detailed characteristics from SPL scoping proposals found in the literature. These characteristics allowed us to compare these approaches, reason about their applicability, and identify existing limitations and research opportunities. Thus, we conducted a systematic literature review alongside snowballing, following a well-defined protocol to retrieve, classify and extract information from the literature. We analyzed a total of 58 studies, identifying 41 different approaches in the field, highlighting their similarities and differences, and establishing a generic scoping process. Furthermore, we discuss research opportunities in the SPL scoping field.}
}
@article{ZAROUR2015180,
title = {An investigation into the best practices for the successful design and implementation of lightweight software process assessment methods: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {101},
pages = {180-192},
year = {2015},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2014.11.041},
url = {https://www.sciencedirect.com/science/article/pii/S0164121214002726},
author = {Mohammad Zarour and Alain Abran and Jean-Marc Desharnais and Abdulrahman Alarifi},
keywords = {software process assessment, systematic literature review, assessment method design},
abstract = {Software process assessment (SPA) is an effective tool to understand an organization's process quality and to explore improvement opportunities. However, the knowledge that underlies the best practices required to develop assessment methods, either lightweight or heavyweight methods, is unfortunately scattered throughout the literature. This paper presents the results of a systematic literature review to organize those recognized as the best practices in a way that helps SPA researchers and practitioners in designing and implementing their assessment methods. Such practices are presented in the literature as assessment requirements, success factors, observations, and lessons learned. Consequently, a set of 38 best practices has been collected and classified into five main categories, namely practices related to SPA methods, support tools, procedures, documentation, and users. While this collected set of best practices is important for designing lightweight as well as heavyweight assessment methods, it is of utmost importance in designing lightweight assessment methods, as the design of which depends on individual experience.}
}
@article{VISHNUBHOTLA2021111013,
title = {Understanding the perceived relevance of capability measures: A survey of Agile Software Development practitioners},
journal = {Journal of Systems and Software},
volume = {180},
pages = {111013},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111013},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221001102},
author = {Sai Datta Vishnubhotla and Emilia Mendes and Lars Lundberg},
keywords = {Individual capability, Team capability, Capability measurement, Agile team formation, Survey, Agile Software Development},
abstract = {Context:
In the light of the swift and iterative nature of Agile Software Development (ASD) practices, establishing deeper insights into capability measurement within the context of team formation is crucial, as the capability of individuals and teams can affect team performance and productivity Although a former Systematic Literature Review (SLR) synthesized the state of the art in relation to capability measurement in ASD – with a focus on selecting individuals to agile teams, and capabilities related to team performance, productivity and success determining to what degree the SLR’s results apply to practice can provide progressive insights to both research and practice.
Objective:
Our study investigates how agile practitioners perceive the relevance of individual and team level measures for characterizing the capability of an agile team and its members. Here, the emphasis was also on selecting individuals to agile teams, and capabilities associated with effective teams in terms of their performance, productivity and success. Furthermore, to scrutinize variations in practitioners’ perceptions, our study further analyzes perceptions across stratified demographic groups.
Method:
We undertook a Web-based survey using a questionnaire built based on the capability measures identified from a previously conducted SLR.
Results:
Our survey responses (60) indicate that 127 individual and 28 team capability measures were considered as relevant by the majority of practitioners. We also identified seven individual and one team capability measure that have not been previously characterized by our SLR. The surveyed practitioners suggested that an agile team member’s responsibility and questioning skills significantly represent the member’s capability.
Conclusion:
Results from our survey align with our SLR’s findings. Measures associated with social aspects were observed to be dominant compared to technical and innovative aspects. Our results can support agile practitioners in their team composition decisions.}
}
@article{ZAINA2022111213,
title = {Preventing accessibility barriers: Guidelines for using user interface design patterns in mobile applications},
journal = {Journal of Systems and Software},
volume = {186},
pages = {111213},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111213},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221002831},
author = {Luciana A.M. Zaina and Renata P.M. Fortes and Vitor Casadei and Leornardo Seiji Nozaki and Débora Maria Barroso Paiva},
keywords = {Accessibility, Mobile application, User interface design pattern, Software engineering, Gray literature review},
abstract = {Mobile applications play an important role in many aspects of life. It is essential to be aware of the software development approaches that can support the design of accessible applications. Their main goal is to ensure that the interactive applications are available to everyone, including people with disabilities, reduced skills, or momentarily induced impairments. This paper aims to identify the accessibility barriers that occur when using design patterns for building user interfaces of mobile apps and propose guidelines to prevent the problems most often encountered. We start by conducting a gray literature review in professional forums and blogs to reveal the difficulties developers face when using mobile user interface design patterns. We thus compiled a catalog which contains the descriptions of 9 user interface design patterns, the accessibility barriers linked to the use of each pattern and the guidelines that can be followed to prevent the problem of these barriers. We carried out an evaluation of the use of the catalog with 60 participants. Our results show that in most cases, the guidelines were correctly applied for the prototyping of mobile user interfaces. The findings also revealed the usefulness and ease-of-use of the guidelines from the perspective of the participants.}
}
@article{AFZAL20161,
title = {Software test process improvement approaches: A systematic literature review and an industrial case study},
journal = {Journal of Systems and Software},
volume = {111},
pages = {1-33},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2015.08.048},
url = {https://www.sciencedirect.com/science/article/pii/S0164121215001910},
author = {Wasif Afzal and Snehal Alone and Kerstin Glocksien and Richard Torkar},
keywords = {Software test process improvement, Systematic literature review, Case study},
abstract = {Software test process improvement (STPI) approaches are frameworks that guide software development organizations to improve their software testing process. We have identified existing STPI approaches and their characteristics (such as completeness of development, availability of information and assessment instruments, and domain limitations of the approaches) using a systematic literature review (SLR). Furthermore, two selected approaches (TPI NEXT and TMMi) are evaluated with respect to their content and assessment results in industry. As a result of this study, we have identified 18 STPI approaches and their characteristics. A detailed comparison of the content of TPI NEXT and TMMi is done. We found that many of the STPI approaches do not provide sufficient information or the approaches do not include assessment instruments. This makes it difficult to apply many approaches in industry. Greater similarities were found between TPI NEXT and TMMi and fewer differences. We conclude that numerous STPI approaches are available but not all are generally applicable for industry. One major difference between available approaches is their model representation. Even though the applied approaches generally show strong similarities, differences in the assessment results arise due to their different model representations.}
}
@article{DADKHAH2020110485,
title = {A systematic literature review on semantic web enabled software testing},
journal = {Journal of Systems and Software},
volume = {162},
pages = {110485},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.110485},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219302596},
author = {Mahboubeh Dadkhah and Saeed Araban and Samad Paydar},
keywords = {Software testing, Test generation, Semantic web, Ontology, Systematic literature review},
abstract = {Software testing, as a major verification and validation activity which revolves around quality tests, is a knowledge-intensive activity. Hence, it is reasonable to expect that it can be improved by effective application of semantic web technologies, e.g., ontologies, which have been frequently used in knowledge engineering activities. The objective of this work is to investigate and provide a better understanding of how semantic web enabled techniques, i.e., the techniques that are based on the effective application of the semantic web technologies, have been used to support software testing activities. For this purpose, a Systematic Literature Review based on a predefined procedure is conducted. A total of 52 primary studies were identified as relevant, which have undergone a thorough meta-analysis with regards to our posed research questions. This study indicates the benefits of semantic web enabled software testing in both industry and academia. It also identifies main software testing activities that can benefit from the semantic web enabled techniques. Furthermore, contributions of such techniques to the testing process are thoroughly examined. Finally, potentials and difficulties of applying these techniques to software testing, along with the promising research directions are discussed.}
}
@article{SHAHIN2014161,
title = {A systematic review of software architecture visualization techniques},
journal = {Journal of Systems and Software},
volume = {94},
pages = {161-185},
year = {2014},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2014.03.071},
url = {https://www.sciencedirect.com/science/article/pii/S0164121214000831},
author = {Mojtaba Shahin and Peng Liang and Muhammad Ali Babar},
keywords = {Software architecture, Software architecture visualization, Visualization techniques},
abstract = {Context
Given the increased interest in using visualization techniques (VTs) to help communicate and understand software architecture (SA) of large scale complex systems, several VTs and tools have been reported to represent architectural elements (such as architecture design, architectural patterns, and architectural design decisions). However, there is no attempt to systematically review and classify the VTs and associated tools reported for SA, and how they have been assessed and applied.
Objective
This work aimed at systematically reviewing the literature on software architecture visualization to develop a classification of VTs in SA, analyze the level of reported evidence and the use of different VTs for representing SA in different application domains, and identify the gaps for future research in the area.
Method
We used systematic literature review (SLR) method of the evidence-based software engineering (EBSE) for reviewing the literature on VTs for SA. We used both manual and automatic search strategies for searching the relevant papers published between 1 February 1999 and 1 July 2011.
Results
We selected 53 papers from the initially retrieved 23,056 articles for data extraction, analysis, and synthesis based on pre-defined inclusion and exclusion criteria. The results from the data analysis enabled us to classify the identified VTs into four types based on the usage popularity: graph-based, notation-based, matrix-based, and metaphor-based VTs. The VTs in SA are mostly used for architecture recovery and architectural evolution activities. We have also identified ten purposes of using VTs in SA. Our results also revealed that VTs in SA have been applied to a wide range of application domains, among which “graphics software” and “distributed system” have received the most attention.
Conclusion
SA visualization has gained significant importance in understanding and evolving software-intensive systems. However, only a few VTs have been employed in industrial practice. This review has enabled us to identify the following areas for further research and improvement: (i) it is necessary to perform more research on applying visualization techniques in architectural analysis, architectural synthesis, architectural implementation, and architecture reuse activities; (ii) it is essential to pay more attention to use more objective evaluation methods (e.g., controlled experiment) for providing more convincing evidence to support the promised benefits of using VTs in SA; (iii) it is important to conduct industrial surveys for investigating how software architecture practitioners actually employ VTs in architecting process and what are the issues that hinder and prevent them from adopting VTs in SA.}
}
@article{TAHIR20132877,
title = {A systematic review on the functional testing of semantic web services},
journal = {Journal of Systems and Software},
volume = {86},
number = {11},
pages = {2877-2889},
year = {2013},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2013.06.064},
url = {https://www.sciencedirect.com/science/article/pii/S0164121213001659},
author = {Abbas Tahir and Davide Tosi and Sandro Morasca},
keywords = {Functional testing, Semantic web services, Testing approach, Systematic literature review},
abstract = {Semantic web services are gaining more attention as an important element of the emerging semantic web. Therefore, testing semantic web services is becoming a key concern as an essential quality assurance measure. The objective of this systematic literature review is to summarize the current state of the art of functional testing of semantic web services by providing answers to a set of research questions. The review follows a predefined procedure that involves automatically searching 5 well-known digital libraries. After applying the selection criteria to the results, a total of 34 studies were identified as relevant. Required information was extracted from the studies and summarized. Our systematic literature review identified some approaches available for deriving test cases from the specifications of semantic web services. However, many of the approaches are either not validated or the validation done lacks credibility. We believe that a substantial amount of work remains to be done to improve the current state of research in the area of testing semantic web services.}
}
@article{ULUDAG2022111473,
title = {Revealing the state of the art of large-scale agile development research: A systematic mapping study},
journal = {Journal of Systems and Software},
volume = {194},
pages = {111473},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111473},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222001601},
author = {Ömer Uludağ and Pascal Philipp and Abheeshta Putta and Maria Paasivaara and Casper Lassenius and Florian Matthes},
keywords = {Agile software development, Large-scale agile development, Systematic mapping study},
abstract = {Context:
Success with agile methods in the small scale has led to an increasing adoption also in large development undertakings and organizations. Recent years have also seen an increasing amount of primary research on the topic, as well as a number of systematic literature reviews. However, there is no systematic overview of the whole research field.
Objective:
This work identifies, classifies, and evaluates the state of the art of research in large-scale agile development.
Methods:
We conducted a systematic mapping study and rigorously selected 136 studies. We designed a classification framework and extracted key information from the studies. We synthesized the obtained data and created an overview of the state of the art.
Results:
This work contributes with (i) a description of large-scale agile endeavors reported in the industry, (ii) a systematic map of existing research in the field, (iii) an overview of influential studies, (iv) an overview of the central research themes, and (v) a research agenda for future research.
Conclusion:
This study portrays the state of the art in large-scale agile development and offers researchers and practitioners a reflection of the past thirteen years of research and practice on the large-scale application of agile methods.}
}
@article{NDUKWE2022111524,
title = {How have views on Software Quality differed over time? Research and practice viewpoints},
journal = {Journal of Systems and Software},
pages = {111524},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111524},
url = {https://www.sciencedirect.com/science/article/pii/S016412122200200X},
author = {Ifeanyi G. Ndukwe and Sherlock A. Licorish and Amjed Tahir and Stephen G. MacDonell},
keywords = {Code snippet quality, Stack overflow, Software quality},
abstract = {Context:
Over the years, there has been debate about what constitutes software quality and how it should be measured. This controversy has caused uncertainty across the software engineering community, affecting levels of commitment to the many potential determinants of quality among developers. An up-to-date catalogue of software quality views could provide developers with contemporary guidelines and templates. In fact, it is necessary to learn about views on the quality of code on frequently used online collaboration platforms (e.g., Stack Overflow), given that the quality of code snippets can affect the quality of software products developed. If quality models are unsuitable for aiding developers because they lack relevance, developers will hold relaxed or inappropriate views of software quality, thereby lacking awareness and commitment to such practices.
Objective:
We aim to explore differences in interest in quality characteristics across research and practice. We also seek to identify quality characteristics practitioners consider important when judging code snippet quality. First, we examine the literature for quality characteristics used frequently for judging software quality, followed by the quality characteristics commonly used by researchers to study code snippet quality. Finally, we investigate quality characteristics used by practitioners to judge the quality of code snippets.
Methods:
We conducted two systematic literature reviews followed by semi-structured interviews of 50 practitioners to address this gap.
Results:
The outcomes of the semi-structured interviews revealed that most practitioners judged the quality of code snippets using five quality dimensions: Functionality, Readability, Efficiency, Security and Reliability. However, other dimensions were also considered (i.e., Reusability, Maintainability, Usability, Compatibility and Completeness). This outcome differed from how the researchers judged code snippet quality.
Conclusion:
Practitioners today mainly rely on code snippets from online code resources, and specific models or quality characteristics are emphasised based on their need to address distinct concerns (e.g., mobile vs web vs standalone applications, regular vs machine learning applications, or open vs closed source applications). Consequently, software quality models should be adapted for the domain of consideration and not seen as one-size-fits-all. This study will lead to targeted support for various clusters of the software development community.}
}
@article{ULLAH201981,
title = {Architectural Tactics for Big Data Cybersecurity Analytics Systems: A Review},
journal = {Journal of Systems and Software},
volume = {151},
pages = {81-118},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.01.051},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219300172},
author = {Faheem Ullah and Muhammad {Ali Babar}},
keywords = {Big data, Cybersecurity, Quality attribute, Architectural tactic},
abstract = {Context
Big Data Cybersecurity Analytics (BDCA) systems leverage big data technologies for analyzing security events data to protect organizational networks, computers, and data from cyber attacks.
Objective
We aimed at identifying the most frequently reported quality attributes and architectural tactics for BDCA systems.
Method
We used Systematic Literature Review (SLR) method for reviewing 74 papers.
Result
Our findings are twofold: (i) identification of 12 most frequently reported quality attributes for BDCA systems; and (ii) identification and codification of 17 architectural tactics for addressing the identified quality attributes. The identified tactics include six performance tactics, four accuracy tactics, two scalability tactics, three reliability tactics, and one security and usability tactic each.
Conclusion
Our study reveals that in the context of BDCA (a) performance, accuracy and scalability are the most important quality concerns (b) data analytics is the most critical architectural component (c) despite the significance of interoperability, modifiability, adaptability, generality, stealthiness, and privacy assurance, these quality attributes lack explicit architectural support (d) empirical investigation is required to evaluate the impact of the codified tactics and explore the quality trade-offs and dependencies among the tactics and (e) the reported tactics need to be modelled using a standardized modelling language such as UML.}
}

@article{BAFANDEHMAYVAN201793,
title = {The state of the art on design patterns: A systematic mapping of the literature},
journal = {Journal of Systems and Software},
volume = {125},
pages = {93-118},
year = {2017},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.11.030},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216302321},
author = {B. {Bafandeh Mayvan} and A. Rasoolzadegan and Z. {Ghavidel Yazdi}},
keywords = {Design patterns, Systematic mapping study, Systematic review},
abstract = {Design patterns are widely used by software developers to build complex systems. Hence, they have been investigated by many researchers in recent decades. This leads to the emergence of various topics in the design patterns field. The objective of this paper is to present an overview of the research efforts on design patterns for those researchers who seek to enter this area. The main contributions are as follows: (a) identifying research topics in design patterns, (b) quantifying the research emphasis on each topic, and (c) describing the demographics of design patterns research. The last secondary study with similar goals in the design patterns field considers the Gang of Four design patterns only. However, the scope of the current study is all of the design patterns. Moreover, our review covers about six additional years and a larger number of publications and venues. In this systematic mapping study, a total of 2775 papers were identified as relevant, and 637 of them were included. According to the results, design patterns can be classified into six different research topics. As a consequence, it is concluded that Pattern Development, Pattern Mining, and Pattern Usage are the most active topics in the field of design patterns.}
}
@article{VALE2016128,
title = {Twenty-eight years of component-based software engineering},
journal = {Journal of Systems and Software},
volume = {111},
pages = {128-148},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2015.09.019},
url = {https://www.sciencedirect.com/science/article/pii/S0164121215002095},
author = {Tassio Vale and Ivica Crnkovic and Eduardo Santana {de Almeida} and Paulo Anselmo da Mota {Silveira Neto} and Yguaratã Cerqueira Cavalcanti and Silvio Romero de Lemos Meira},
keywords = {Systematic mapping study, Component-based software engineering, Component-based software development, Software component},
abstract = {The idea of developing software components was envisioned more than forty years ago. In the past two decades, Component-Based Software Engineering (CBSE) has emerged as a distinguishable approach in software engineering, and it has attracted the attention of many researchers, which has led to many results being published in the research literature. There is a huge amount of knowledge encapsulated in conferences and journals targeting this area, but a systematic analysis of that knowledge is missing. For this reason, we aim to investigate the state-of-the-art of the CBSE area through a detailed literature review. To do this, 1231 studies dating from 1984 to 2012 were analyzed. Using the available evidence, this paper addresses five dimensions of CBSE: main objectives, research topics, application domains, research intensity and applied research methods. The main objectives found were to increase productivity, save costs and improve quality. The most addressed application domains are homogeneously divided between commercial-off-the-shelf (COTS), distributed and embedded systems. Intensity of research showed a considerable increase in the last fourteen years. In addition to the analysis, this paper also synthesizes the available evidence, identifies open issues and points out areas that call for further research.}
}
@article{SCHRODER201879,
title = {Architecture enforcement concerns and activities - An expert study},
journal = {Journal of Systems and Software},
volume = {145},
pages = {79-97},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.08.025},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218301614},
author = {Sandra Schröder and Mohamed Soliman and Matthias Riebisch},
keywords = {Software architecture, Architecture enforcement, Software architecture in industry, Architecture erosion, Empirical study},
abstract = {Architecture enforcement is concerned with the correct and seamless implementation of architecture design decisions in order to ensure software quality. In a previous study, we conducted an empirical study in order to gain insight into the industrial practice of architecture enforcement. There, we asked 12 software architects from industry about their experience with the architecture enforcement process. As a result, we identified architecture enforcement concerns and activities. In this paper, we extend our contributions of the existing study. Firstly, we conducted five additional interviews with software architects from two different domains, namely the enterprise application and the automotive domain. This adds new architecture concerns and activities to the existing list. Secondly, we conducted a literature review. We compared our findings from the interviews with the results from the literature review and evaluated how architects’ enforcement concerns and activities are discussed in literature. We found that several concerns and activities are already known from literature, but are not viewed in the context of architecture enforcement by the software architecture community. Lastly, we connected the discovered architecture concerns and activities with each other. Those relationships determine the reason why a specific architecture enforcement activity is conducted.}
}
@article{EKELHART20081715,
title = {XML security – A comparative literature review},
journal = {Journal of Systems and Software},
volume = {81},
number = {10},
pages = {1715-1724},
year = {2008},
note = {Selected papers from the 30th Annual International Computer Software and Applications Conference (COMPSAC), Chicago, September 7–21, 2006},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2007.12.763},
url = {https://www.sciencedirect.com/science/article/pii/S0164121207003226},
author = {Andreas Ekelhart and Stefan Fenz and Gernot Goluch and Markus Steinkellner and Edgar Weippl},
keywords = {XML security, XML encryption, XML signature, XML key management, Web services, Privacy},
abstract = {Since the turn of the millenium, working groups of the W3C have been concentrating on the development of XML-based security standards, which are paraphrased as XML security. XML security consists of three recommendations: XML (digital) signature, XML encryption and XML key management specification (XKMS), all of them published by the W3C. By means of a review of the available literature the authors draw several conclusions about the status quo of XML security. Furthermore, the current state and focuses of research as well as the existing challenges are derived. Trends to different application areas – e.g. use of XML security for mobile computing – are also outlined. Based on this information the analyzed results are discussed and a future outlook is predicted.}
}
@article{MARO201885,
title = {Software traceability in the automotive domain: Challenges and solutions},
journal = {Journal of Systems and Software},
volume = {141},
pages = {85-110},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.03.060},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218300608},
author = {Salome Maro and Jan-Philipp Steghöfer and Miroslaw Staron},
keywords = {Traceability, Automotive, Safety, ISO 26262, Automotive SPICE},
abstract = {In the automotive domain, the development of all safety-critical systems has to comply with safety standards such as ISO 26262. These standards require established traceability, the ability to relate artifacts created during development of a system, to ensure resulting systems are well-tested and therefore safe. This paper contrasts general traceability challenges and solutions with those specific to the automotive domain, and investigates how they manifest in practice. We combine three data sources: a tertiary literature review to identify general challenges and solutions; a case study with an automotive supplier as validation for how the challenges and solutions are experienced in practice; and a multi-vocal literature review to identify challenges and solutions specific to the automotive domain. We found 22 challenges and 16 unique solutions in the reviews. 17 challenges were identified in the case study; six remain unsolved. We discuss challenges and solutions from the perspectives of academia, tool vendors, consultants and users, and identify differences between scientific and “grey” literature. We discuss why challenges remain unsolved and propose solutions. Our findings indicate that there is a significant overlap between general traceability challenges and those in the automotive domain but that they are experienced differently.}
}
@article{MULLER20102128,
title = {Software Process Improvement as organizational change: A metaphorical analysis of the literature},
journal = {Journal of Systems and Software},
volume = {83},
number = {11},
pages = {2128-2146},
year = {2010},
note = {Interplay between Usability Evaluation and Software Development},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2010.06.017},
url = {https://www.sciencedirect.com/science/article/pii/S0164121210001664},
author = {Sune Dueholm Müller and Lars Mathiassen and Hans Henrik Balshøj},
keywords = {Software Process Improvement, Organizational change, Metaphors, Literature review, Images of Organization},
abstract = {Software Process Improvement (SPI) typically involves rather complex organizational changes. Acknowledging that managers can approach these changes in quite different ways, this paper addresses the following question: what perspectives do the research literature offer on SPI as organizational change and how is this knowledge presented and published? To answer this question, we analyzed SPI research publications with a main emphasis on organizational change using Gareth Morgan's organizational metaphors (1996) as analytical lenses. In addition, we characterized each article along the following dimensions: knowledge orientation (normative versus descriptive), theoretical emphasis (high versus low), main audience (practitioner versus academic), geographical origin (Scandinavia, the Americas, Europe, or the Asia-Pacific), and publication level (high versus low ranked journal). The review demonstrates that the literature as a whole is firmly grounded in both theory and practice, it appropriately targets both practitioner and academic audiences, and Scandinavian and American researchers are the main contributors. However, the distribution of articles across Morgan's metaphors is uneven and reveals knowledge gaps that present new avenues for research. The current literature offers important insights into organizational change in SPI when viewed through machine, organism, flux and transformation, and brain metaphors. Practitioners may use these articles to guide SPI initiatives. In contrast, the impact of culture, dominance, psychic prison, and politics in SPI has only received scant attention. We argue that these perspectives could offer important additional insights into the challenges involved in managing SPI. Researchers are therefore advised to engage in new SPI research based on one or more of these perspectives. Overall, the paper offers research directions and management lessons, and it provides a roadmap to help identify insights and specific articles related to SPI as organizational change.}
}
@article{SHAHIN2020110752,
title = {Architectural Design Space for Modelling and Simulation as a Service: A Review},
journal = {Journal of Systems and Software},
volume = {170},
pages = {110752},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110752},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220301746},
author = {Mojtaba Shahin and M. Ali Babar and Muhammad Aufeef Chauhan},
keywords = {Modelling and Simulation as a Service, MSaaS, Architecture, Systematic review},
abstract = {Modelling and Simulation as a Service (MSaaS) is a promising approach to deploy and execute Modelling and Simulation (M&S) applications quickly and on-demand. An appropriate software architecture is essential to deliver quality M&S applications following the MSaaS concept to a wide range of users. This study aims to characterize the state-of-the-art MSaaS architectures by conducting a systematic review of 31 papers published from 2010 to 2018. Our findings reveal that MSaaS applications are mainly designed using layered architecture style, followed by service-oriented architecture, component-based architecture, and pluggable component-based architecture. We also found that interoperability and deployability have the greatest importance in the architecture of MSaaS applications. In addition, our study indicates that the current MSaaS architectures do not meet the critical user requirements of modern M&S applications appropriately. Based on our results, we recommend that there is a need for more effort and research to (1) design the user interfaces that enable users to build and configure simulation models with minimum effort and limited domain knowledge, (2) provide mechanisms to improve the deployability of M&S applications, and (3) gain a deep insight into how M&S applications should be architected to respond to the emerging user requirements in the military domain.}
}
@article{RASPOTNIG20131124,
title = {Comparing risk identification techniques for safety and security requirements},
journal = {Journal of Systems and Software},
volume = {86},
number = {4},
pages = {1124-1151},
year = {2013},
note = {SI : Software Engineering in Brazil: Retrospective and Prospective Views},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2012.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0164121212003305},
author = {Christian Raspotnig and Andreas Opdahl},
keywords = {Risk identification, Safety, Security, Technique, Requirement elicitation, Comparison},
abstract = {When developing systems where safety and security are important aspects, these aspects have to be given special attention throughout the development, in particular in the requirements phase. There are many similar techniques within the safety and security fields, but few comparisons about what lessons that could be learnt and benefits to be gained. In this paper different techniques for identifying risk, hazard and threat of computer-supported systems are compared. This is done by assessing the techniques’ ability to identify different risks in computer-supported systems in the environment where they operate. The purpose of this paper is therefore to investigate whether and how the techniques can mutually strengthen each other. The result aids practitioners in the selection and combination of techniques and researchers in focusing on gaps between the two fields. Among other things, the findings suggest that many safety techniques enforce a creative and systematic process by applying guide-words and structuring the results in worksheets, while security techniques tend to integrate system models with security models.}
}
@article{JIA2016206,
title = {5W+1H pattern: A perspective of systematic mapping studies and a case study on cloud software testing},
journal = {Journal of Systems and Software},
volume = {116},
pages = {206-219},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2015.01.058},
url = {https://www.sciencedirect.com/science/article/pii/S0164121215000370},
author = {Changjiang Jia and Yan Cai and Yuen Tak Yu and T.H. Tse},
keywords = {5W+1H pattern, Cloud software testing, Systematic mapping study},
abstract = {A common type of study used by researchers to map out the landscape of a research topic is known as mapping study. Such a study typically begins with an exploratory search on the possible ideas of the research topic, which is often done in an unsystematic manner. Hence, the activity of formulating research questions in mapping studies is ill-defined, rendering it difficult for researchers who are new to the topic. There is a need to guide them kicking off a mapping study of an unfamiliar domain. This paper proposes a 5W+1H pattern to help investigators systematically examine a generic set of dimensions in a mapping study toward the formulation of research questions before identifying, reading, and analyzing sufficient articles of the topic. We have validated the feasibility of our proposal by conducting a case study of a mapping study on cloud software testing, that is, software testing for and on cloud computing platforms. The case study reveals that the 5W+1H pattern can lead investigators to define a set of systematic, generic, and complementary research questions, enabling them to kick off and expedite the mapping study process in a well-defined manner. We also share our experiences and lessons learned from our case study on the use of the 5W+1H pattern in mapping studies.}
}
@article{AJILA20071517,
title = {Empirical study of the effects of open source adoption on software development economics},
journal = {Journal of Systems and Software},
volume = {80},
number = {9},
pages = {1517-1529},
year = {2007},
note = {Evaluation and Assessment in Software Engineering},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2007.01.011},
url = {https://www.sciencedirect.com/science/article/pii/S0164121207000076},
author = {Samuel A. Ajila and Di Wu},
keywords = {Open source software, Reuse, Software process improvement, Adoption, Quality, Productivity, Measurement and economics},
abstract = {In this paper, we present the results of empirical study of the effects of open source software (OSS) components reuse on software development economics. Specifically, we examined three economic factors – cost, productivity, and quality. This study started with an extensive literature review followed by an exploratory study conducted through interviews with 18 senior project/quality managers, and senior software developers. Then, the result of the literature review and the exploratory study was used to formulate research model, hypotheses, and survey questionnaire. Software intensive companies from Canada and the US were targeted for this study. The period of study was between September 2004 and March 2006. Our findings show that there are strong significant statistical correlations between the factors of OSS components reuse and software development economics. The conclusion from this study shows that software organizations can achieve some economic gains in terms of software development productivity and product quality if they implement OSS components reuse adoption in a systematic way. A big lesson learned in this study is that OSS components are of highest quality and that open source community is not setting a bad example (contrary to some opinion) so far as ‘good practices’ are concerned.}
}
@article{MAGDALENO2012351,
title = {Reconciling software development models: A quasi-systematic review},
journal = {Journal of Systems and Software},
volume = {85},
number = {2},
pages = {351-369},
year = {2012},
note = {Special issue with selected papers from the 23rd Brazilian Symposium on Software Engineering},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2011.08.028},
url = {https://www.sciencedirect.com/science/article/pii/S0164121211002287},
author = {Andréa Magalhães Magdaleno and Cláudia Maria Lima Werner and Renata Mendes de Araujo},
keywords = {Systematic review, Software process, Reconciliation among development models, Plan-driven, Agile, Free/open source software},
abstract = {Purpose
The purpose of this paper is to characterize reconciliation among the plan-driven, agile, and free/open source software models of software development.
Design/methodology/approach
An automated quasi-systematic review identified 42 papers, which were then analyzed.
Findings
The main findings are: there exist distinct – organization, group and process – levels of reconciliation; few studies deal with reconciliation among the three models of development; a significant amount of work addresses reconciliation between plan-driven and agile development; several large organizations (such as Microsoft, Motorola, and Philips) are interested in trying to combine these models; and reconciliation among software development models is still an open issue, since it is an emerging area and research on most proposals is at an early stage.
Research limitations
Automated searches may not capture relevant papers in publications that are not indexed. Other data sources not amenable to execution of the protocol were not used. Data extraction was performed by only one researcher, which may increase the risk of threats to internal validity.
Implications
This characterization is important for practitioners wanting to be current with the state of research. This review will also assist the scientific community working with software development processes to build a common understanding of the challenges that must be faced, and to identify areas where research is lacking. Finally, the results will be useful to software industry that is calling for solutions in this area.
Originality/value
There is no other systematic review on this subject, and reconciliation among software development models is an emerging area. This study helps to identify and consolidate the work done so far and to guide future research. The conclusions are an important step towards expanding the body of knowledge in the field.}
}
@article{DEY2021110941,
title = {Multilayered review of safety approaches for machine learning-based systems in the days of AI},
journal = {Journal of Systems and Software},
volume = {176},
pages = {110941},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.110941},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221000388},
author = {Sangeeta Dey and Seok-Won Lee},
keywords = {Autonomous systems, Intelligent software systems, Machine learning, Safety analysis, Software engineering},
abstract = {The unprecedented advancement of artificial intelligence (AI) in recent years has altered our perspectives on software engineering and systems engineering as a whole. Nowadays, software-intensive intelligent systems rely more on a learning model than thousands of lines of codes. Such alteration has led to new research challenges in the engineering process that can ensure the safe and beneficial behavior of AI systems. This paper presents a literature survey of the significant efforts made in the last fifteen years to foster safety in complex intelligent systems. This survey covers relevant aspects of AI safety research including safety requirements engineering, safety-driven design at both system and machine learning (ML) component level, validation and verification from the perspective of software and system engineers. We categorize these research efforts based on a three-layered conceptual framework for developing and maintaining AI systems. We also perform a gap analysis to emphasize the open research challenges in ensuring safe AI. Finally, we conclude the paper by providing future research directions and a road map for AI safety.}
}
@article{PIETRANTUONO2020110462,
title = {On the testing resource allocation problem: Research trends and perspectives},
journal = {Journal of Systems and Software},
volume = {161},
pages = {110462},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.110462},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219302365},
author = {Roberto Pietrantuono},
keywords = {Testing, Resource allocation, Reliability allocation, Literature review, Test planning, Survey},
abstract = {In testing a software application, a primary concern is how to effectively plan the assignment of resources available for testing to the software components so as to achieve a target goal under given constraints. In the literature, this is known as testing resources allocation problem (TRAP). Researchers spent a lot of effort to propose models for supporting test engineers in this task, and a variety of solutions exist to assess the best trade-off between testing time, cost and quality of delivered products. This article presents a systematic mapping study aimed at systematically exploring the TRAP research area in order to provide an overview on the type of research performed and on results currently available. A sample of 68 selected studies has been classified and analyzed according to defined dimensions. Results give an overview of the state of the art, provide guidance to improve practicability and allow outlining a set of directions for future research and applications of TRAP solutions.}
}
@article{STAHL201448,
title = {Modeling continuous integration practice differences in industry software development},
journal = {Journal of Systems and Software},
volume = {87},
pages = {48-59},
year = {2014},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2013.08.032},
url = {https://www.sciencedirect.com/science/article/pii/S0164121213002276},
author = {Daniel Ståhl and Jan Bosch},
keywords = {Continuous integration, Agile software development},
abstract = {Continuous integration is a software practice where developers integrate frequently, at least daily. While this is an ostensibly simple concept, it does leave ample room for interpretation: what is it the developers integrate with, what happens when they do, and what happens before they do? These are all open questions with regards to the details of how one implements the practice of continuous integration, and it is conceivable that not all such implementations in the industry are alike. In this paper we show through a literature review that there are differences in how the practice of continuous integration is interpreted and implemented from case to case. Based on these findings we propose a descriptive model for documenting and thereby better understanding implementations of the continuous integration practice and their differences. The application of the model to an industry software development project is then described in an illustrative case study.}
}
@article{DEOLIVEIRANETO2019246,
title = {Evolution of statistical analysis in empirical software engineering research: Current state and steps forward},
journal = {Journal of Systems and Software},
volume = {156},
pages = {246-267},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219301451},
author = {Francisco Gomes {de Oliveira Neto} and Richard Torkar and Robert Feldt and Lucas Gren and Carlo A. Furia and Ziwei Huang},
keywords = {Empirical software engineering, Statistical methods, Practical significance, Semi-automated literature review},
abstract = {Software engineering research is evolving and papers are increasingly based on empirical data from a multitude of sources, using statistical tests to determine if and to what degree empirical evidence supports their hypotheses. To investigate the practices and trends of statistical analysis in empirical software engineering (ESE), this paper presents a review of a large pool of papers from top-ranked software engineering journals. First, we manually reviewed 161 papers and in the second phase of our method, we conducted a more extensive semi-automatic classification of papers spanning the years 2001–2015 and 5196 papers. Results from both review steps was used to: i) identify and analyse the predominant practices in ESE (e.g., using t-test or ANOVA), as well as relevant trends in usage of specific statistical methods (e.g., nonparametric tests and effect size measures) and, ii) develop a conceptual model for a statistical analysis workflow with suggestions on how to apply different statistical methods as well as guidelines to avoid pitfalls. Lastly, we confirm existing claims that current ESE practices lack a standard to report practical significance of results. We illustrate how practical significance can be discussed in terms of both the statistical analysis and in the practitioner’s context.}
}
@article{RAHIMI2022111421,
title = {Visualization of aggregated information to support class-level software evolution},
journal = {Journal of Systems and Software},
volume = {192},
pages = {111421},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111421},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222001297},
author = {Mona Rahimi and Michael Vierhauser},
keywords = {Code changes, Change visualization, Software evolution},
abstract = {Context:
Software is inherently prone to constant change, especially in the source code, making it difficult for developers to keep track of changes performed over time and to fully understand their implications.
Objective:
To this end, we present an Eclipse plug-in for visualizing heterogeneous information, collected from multiple sources, at different levels of granularity. This visualization provides a single graphical representation of a system’s change histories over multiple versions, allowing developers to identify the previous and present dependencies in the system, while adding new or removing and modifying the current functionalities of a software. Summarizing and associating the relevant changes in a single graph, further supports developers, not familiar with the overall system, to conduct a self-study and explore the systems design and changes of its functionality over time.
Method:
Our tool, DejaVu, initially infers and further visualizes change scenarios that have been applied to a given class in source code, across multiple versions of a software. DejaVu additionally augments the change information with prior commits from GitHub repositories, as well as associated issues from Jira issue tracking system.
Evaluation:
As part of the evaluation, we conducted a controlled experiment, recruiting participants with research or industrial programming experiences. The participants were asked to investigate and assess a set of change stories with and without the use of the DejaVu. As such, we empirically evaluated the impact of DejaVu in alleviating developers’ understanding of code class-level changes across multiple versions.
Results:
Our results showed an average of 52% reduction in completion time and a 51% increase in correctness of several change-comprehension tasks once, users adopted DejaVu in comparison to the manual completion of the same tasks. A student’s t-test verified the significant improvement in time and correctness of the tasks with p-values of 0.01 and 0.002.
Conclusion:
Visualizing aggregated information from multiple sources provides developers with a more comprehensive intuition of the change and its rationale, facilitating software maintenance tasks.}
}
@article{JANNACH2014129,
title = {Avoiding, finding and fixing spreadsheet errors – A survey of automated approaches for spreadsheet QA},
journal = {Journal of Systems and Software},
volume = {94},
pages = {129-150},
year = {2014},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2014.03.058},
url = {https://www.sciencedirect.com/science/article/pii/S0164121214000788},
author = {Dietmar Jannach and Thomas Schmitz and Birgit Hofer and Franz Wotawa},
keywords = {Spreadsheet, Quality assurance, Tool support},
abstract = {Spreadsheet programs can be found everywhere in organizations and they are used for a variety of purposes, including financial calculations, planning, data aggregation and decision making tasks. A number of research surveys have however shown that such programs are particularly prone to errors. Some reasons for the error-proneness of spreadsheets are that spreadsheets are developed by end users and that standard software quality assurance processes are mostly not applied. Correspondingly, during the last two decades, researchers have proposed a number of techniques and automated tools aimed at supporting the end user in the development of error-free spreadsheets. In this paper, we provide a review of the research literature and develop a classification of automated spreadsheet quality assurance (QA) approaches, which range from spreadsheet visualization, static analysis and quality reports, over testing and support to model-based spreadsheet development. Based on this review, we outline possible opportunities for future work in the area of automated spreadsheet QA.}
}
@article{CAIVANO2018295,
title = {Supporting end users to control their smart home: design implications from a literature review and an empirical investigation},
journal = {Journal of Systems and Software},
volume = {144},
pages = {295-313},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.06.035},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218301262},
author = {Danilo Caivano and Daniela Fogli and Rosa Lanzilotti and Antonio Piccinno and Fabio Cassano},
keywords = {Ambient intelligence, Internet of things, Smart home, Rule-based paradigm, End-user development},
abstract = {Designing tools that allow end users to easily control and manage a smart home is a critical issue that researchers in Ambient Intelligence and Internet of Things have to address. Because of the variety of available solutions, with their advantages and limitations, it is not straightforward to understand which are the requirements that must be satisfied to effectively support end users. This paper aims to contribute to this topic through a systematic and rigorous activity based on two main pillars of the empirical research in software engineering: i) a literature review addressing design and evaluation of tools for smart home control oriented to end users, and ii) an experimental study in which three tools, that emerged from the literature review as the most suitable and widespread, were compared in order to identify the interaction mechanisms that end users appreciate most. On the basis of the obtained results, a set of design implications that may drive the development of future tools for smart home control and management are presented.}
}
@article{RABISER2017309,
title = {A comparison framework for runtime monitoring approaches},
journal = {Journal of Systems and Software},
volume = {125},
pages = {309-321},
year = {2017},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.12.034},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216302618},
author = {Rick Rabiser and Sam Guinea and Michael Vierhauser and Luciano Baresi and Paul Grünbacher},
keywords = {Runtime monitoring, Literature review, Comparison framework},
abstract = {The full behavior of complex software systems often only emerges during operation. They thus need to be monitored at run time to check that they adhere to their requirements. Diverse runtime monitoring approaches have been developed in various domains and for different purposes. Their sheer number and heterogeneity, however, make it hard to find the right approach for a specific application or purpose. The aim of our research therefore was to develop a comparison framework for runtime monitoring approaches. Our framework is based on an analysis of the literature and existing taxonomies for monitoring languages and patterns. We use examples from existing monitoring approaches to explain the framework. We demonstrate its usefulness by applying it to 32 existing approaches and by comparing 3 selected approaches in the light of different monitoring scenarios. We also discuss perspectives for researchers.}
}
@article{SANTOS2018450,
title = {A systematic review on the code smell effect},
journal = {Journal of Systems and Software},
volume = {144},
pages = {450-477},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.07.035},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218301444},
author = {José Amancio M. Santos and João B. Rocha-Junior and Luciana Carla Lins Prates and Rogeres Santos do Nascimento and Mydiã Falcão Freitas and Manoel Gomes de Mendonça},
keywords = {Code smell, Systematic review, Thematic synthesis},
abstract = {Context: Code smell is a term commonly used to describe potential problems in the design of software. The concept is well accepted by the software engineering community. However, some studies have presented divergent findings about the usefulness of the smell concept as a tool to support software development tasks. The reasons of these divergences have not been considered because the studies are presented independently. Objective: To synthesize current knowledge related to the usefulness of the smell concept. We focused on empirical studies investigating how smells impact the software development, the code smell effect. Method: A systematic review about the smell effect is carried out. We grouped the primary studies findings in a thematic map. Result: The smell concept does not support the evaluation of quality design in practice activities of software development. There is no strong evidence correlating smells and some important software development attributes, such as effort in maintenance. Moreover, the studies point out that human agreement on smell detection is low. Conclusion: In order to improve analysis on the subject, the area needs to better outline: (i) factors affecting human evaluation of smells; and (ii) a classification of types of smells, grouping them according to relevant characteristics.}
}
@article{LUNDELL2004271,
title = {Changing perceptions of CASE technology},
journal = {Journal of Systems and Software},
volume = {72},
number = {2},
pages = {271-280},
year = {2004},
issn = {0164-1212},
doi = {https://doi.org/10.1016/S0164-1212(03)00087-6},
url = {https://www.sciencedirect.com/science/article/pii/S0164121203000876},
author = {Björn Lundell and Brian Lings},
keywords = {CASE technology, Literature review, Software development, Evolution of CASE technology, CASE adoption},
abstract = {The level to which CASE technology has been successfully deployed in IS and software development organisations has been at best variable. Much has been written about an apparent mismatch between user expectations of the technology and the products which are developed for the growing marketplace. In this paper we explore how this tension has developed over time, with the aim of identifying and characterising the major factors contributing to it. We identify three primary themes: volatility and plurality in the marketplace; the close relationship between tools and development methods; and the context sensitivity of feature assessment. By exploring the tension and developing these themes we hope to further the debate on how to improve evaluation of CASE prior to adoption.}
}
@article{ZIELSKE2021110950,
title = {Application of agile methods in traditional logistics companies and logistics startups: Results from a German Delphi Study},
journal = {Journal of Systems and Software},
volume = {177},
pages = {110950},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.110950},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221000479},
author = {Malena Zielske and Tobias Held},
keywords = {Agile methods, Logistics, Traditional companies, Startups, Delphi Study},
abstract = {To meet changing requirements and rising product complexity, a growing number of traditional logistics companies and logistics startups are increasing their agility through the use of progressively agile methods. The objective of the Delphi Study is to assess how traditional logistics companies and logistics startups use agile methods in their IT departments, what benefits they realise and what challenges they face introducing and using agile methods. A modified Delphi Study was conducted over three complementary rounds as an iterative expert judgment process. After the analysis of the results, insights were gained on the following points covering traditional logistics companies and logistics startups: (a) used agile methods and practices, (b) perceived benefits that these methods offer and (c) challenges of applying these methods. The results of the Delphi Study show that traditional logistics companies as well as logistics startups chose similar agile methods and practices. Both company types aim to realise mainly the same benefits but face different challenges regarding the introduction of agile methods. The Delphi Study’s originality lies in its contribution to the largely unexplored area of agility in the field of logistics.}
}
@article{RIBEIRO2022111137,
title = {Moderator factors of software security and performance verification},
journal = {Journal of Systems and Software},
volume = {184},
pages = {111137},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111137},
url = {https://www.sciencedirect.com/science/article/pii/S016412122100234X},
author = {Victor Vidigal Ribeiro and Daniela Soares Cruzes and Guilherme Horta Travassos},
keywords = {Security, Performance, Software verification, Software testing, Evidence-based software engineering},
abstract = {Context:
Security and performance are critical software non-functional requirements. Therefore, verification activities should be included in the development process to identify related defects, avoiding failures after deployment. However, there is a lack of understanding on factors moderating the security and performance verification, which jeopardizes organizations to improve their verification activities to assure the releasing of software fulfilling these requirements.
Objective:
To identify moderator factors influencing security and performance verification and actions to promote them.
Methods:
Case study to identify security and performance moderators factors. Rapid Literature Reviews with Snowballing to strengthen moderator factors confidence. Practitioners Survey to classify the moderator factors relevance.
Results:
Identification of eight security and performance moderator factors regarding organizational awareness, cross-functional team, suitable requirements, support tools, verification environment, verification methodology, verification planning, and reuse practices. Rapid Reviews confirmed the moderator factors and revealed actions to promote each. A survey with 37 practitioners allowed us to classify the moderator factors and their actions regarding their relevancy.
Conclusions:
The moderator factors can be considered key points to software development organizations implement/improve security and performance verification activities in regular software systems. Further investigation is necessary to support the understanding of these moderator factors when building modern software systems.}
}
@article{TRIPATHI2018130,
title = {An anatomy of requirements engineering in software startups using multi-vocal literature and case survey},
journal = {Journal of Systems and Software},
volume = {146},
pages = {130-151},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.08.059},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218301729},
author = {Nirnaya Tripathi and Eriks Klotins and Rafael Prikladnicki and Markku Oivo and Leandro Bento Pompermaier and Arun Sojan Kudakacheril and Michael Unterkalmsteiner and Kari Liukkunen and Tony Gorschek},
keywords = {Requirements engineering, Software startups, Multi-vocal literature review, Case survey},
abstract = {Context: Software startups aim to develop innovative products, grow rapidly, and thus become important in the development of economy and jobs. Requirements engineering (RE) is a key process area in software development, but its effects on software startups are unclear. Objective: The main objective of this study was to explore how RE (elicitation, documentation, prioritization and validation) is used in software startups. Method: A multi-vocal literature review (MLR) was used to find scientific and gray literature. In addition, a case survey was employed to gather empirical data to reach this study’s objective. Results: In the MLR, 36 primary articles were selected out of 28,643 articles. In the case survey, 80 respondents provided information about software startup cases across the globe. Data analysis revealed that during RE processes, internal sources (e.g., for source), analyses of similar products (e.g., elicitation), uses of informal notes (e.g., for documentation), values to customers, products and stakeholders (e.g., for prioritization) and internal reviews/prototypes (e.g., for validation) were the most used techniques. Conclusion: After an analysis of primary literature, it was concluded that research on this topic is still in early stages and more systematic research is needed. Furthermore, few topics were suggested for future research.}
}
@article{PARIZI2022111217,
title = {How has design thinking being used and integrated into software development activities? A systematic mapping},
journal = {Journal of Systems and Software},
volume = {187},
pages = {111217},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111217},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222000024},
author = {Rafael Parizi and Matheus Prestes and Sabrina Marczak and Tayana Conte},
keywords = {Software development, User-centered design, Design thinking, Literature review, Systematic mapping study},
abstract = {Software companies have been using Design Thinking (DT) as a user-centered design approach, putting the user at the center of the software development process. In this article, we report a Systematic Mapping Study to investigate the use of DT in software development. We evaluated 127 papers from 2010 to 2021. We analyzed how DT is integrated in software development, what are the models and techniques, what are the criteria used for selecting DT techniques, and what are the key points that DT practitioners should be aware of when using DT. As a result, we identified 3 strategies to integrate DT in software development, 16 models, and 85 techniques. We also found that the selection of techniques is related to the models’ working spaces being performed, and identified 7 criteria used for selecting DT techniques. Furthermore, we summarized 16 key points that DT practitioners should pay attention when using DT, and we proposed 4 takeaways for applying DT in software development Thus, our study contributes to DT practitioners by providing information to be used either as a starting point, or to integrate it into activities already performed by teams, or as a strategy to foster changes in the entire organization’s mindset.}
}
@article{GACITUA20191,
title = {FM-CF: A framework for classifying feature model building approaches},
journal = {Journal of Systems and Software},
volume = {154},
pages = {1-21},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.04.026},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219300767},
author = {Ricardo Gacitúa and Samuel Sepúlveda and Raúl Mazo},
keywords = {Feature model, Software product lines, Framework, Classification, Models},
abstract = {Software product line engineering has emerged as a prominent software engineering paradigm, as it comprises a set of core assets sharing functionality and quality attributes. Feature modelling is one of the most frequently used techniques for modelling the variability within a software product line. There are several proposals for building Feature Models which rely on semi-automated or fully automated means. Unfortunately, automatic feature model construction has been addressed from different viewpoints, so it is not easy to know which is the best approach for automating the building of variability models. In fact, there is no clarity regarding common elements, and the main differences that characterise such approaches. Additionally, the wide variety of terms used to refer to the process of building a Feature Model (e.g. synthesis, location, re-engineering, and weaving) means that approaches are varied and very heterogeneous, making them complex to understand and classify. This paper introduces FM-CF, which is a Conceptual experience-based Framework for classifying approaches for the automatic building of Feature Models. The framework considers a set of categories mainly focused on characterising some aspects, such as input sources, methods and techniques, results, and types of evaluation. A literature review of (semi-) automated Feature Model construction was performed to identify approaches for building Feature Models by (semi-)automatic means, and the main terms used by those approaches. Then the completeness of the framework was evaluated by mapping the set of dimensions and their items, and the terms extracted from the literature. The conceptual framework provides guidance to researchers for choosing the appropriate aspects with which to build Feature Models, and helps in the understanding and clarification of the proposed approaches.}
}
@article{DANGLOT2019110398,
title = {A snowballing literature study on test amplification},
journal = {Journal of Systems and Software},
volume = {157},
pages = {110398},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.110398},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219301736},
author = {Benjamin Danglot and Oscar Vera-Perez and Zhongxing Yu and Andy Zaidman and Martin Monperrus and Benoit Baudry},
keywords = {Test amplification, Test augmentation, Test optimization, Test regeneration, Automatic testing},
abstract = {The adoption of agile approaches has put an increased emphasis on testing, resulting in extensive test suites. These suites include a large number of tests, in which developers embed knowledge about meaningful input data and expected properties as oracles. This article surveys works that exploit this knowledge to enhance manually written tests with respect to an engineering goal (e.g., improve coverage or refine fault localization). While these works rely on various techniques and address various goals, we believe they form an emerging and coherent field of research, which we coin “test amplification”. We devised a first set of papers from DBLP, searching for all papers containing “test” and “amplification” in their title. We reviewed the 70 papers in this set and selected the 4 papers that fit the definition of test amplification. We use them as the seeds for our snowballing study, and systematically followed the citation graph. This study is the first that draws a comprehensive picture of the different engineering goals proposed in the literature for test amplification. We believe that this survey will help researchers and practitioners entering this new field to understand more quickly and more deeply the intuitions, concepts and techniques used for test amplification.}
}
@article{KHURUM20091982,
title = {A systematic review of domain analysis solutions for product lines},
journal = {Journal of Systems and Software},
volume = {82},
number = {12},
pages = {1982-2003},
year = {2009},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2009.06.048},
url = {https://www.sciencedirect.com/science/article/pii/S016412120900154X},
author = {Mahvish Khurum and Tony Gorschek},
keywords = {Systematic review, Domain analysis, Domain modeling, Domain scoping, Empirical evidence, Usability, Usefulness},
abstract = {Domain analysis is crucial and central to software product line engineering (SPLE) as it is one of the main instruments to decide what to include in a product and how it should fit in to the overall software product line. For this reason many domain analysis solutions have been proposed both by researchers and industry practitioners. Domain analysis comprises various modeling and scoping activities. This paper presents a systematic review of all the domain analysis solutions presented until 2007. The goal of the review is to analyze the level of industrial application and/or empirical validation of the proposed solutions with the purpose of mapping maturity in terms of industrial application, as well as to what extent proposed solutions might have been evaluated in terms of usability and usefulness. The finding of this review indicates that, although many new domain analysis solutions for software product lines have been proposed over the years, the absence of qualitative and quantitative results from empirical application and/or validation makes it hard to evaluate the potential of proposed solutions with respect to their usability and/or usefulness for industry adoption. The detailed results of the systematic review can be used by individual researchers to see large gaps in research that give opportunities for future work, and from a general research perspective lessons can be learned from the absence of validation as well as from good examples presented. From an industry practitioner view, the results can be used to gauge as to what extent solutions have been applied and/or validated and in what manner, both valuable as input prior to industry adoption of a domain analysis solution.}
}
@article{FERNANDEZSANCHEZ201722,
title = {Identification and analysis of the elements required to manage technical debt by means of a systematic mapping study},
journal = {Journal of Systems and Software},
volume = {124},
pages = {22-38},
year = {2017},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.10.018},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216302138},
author = {Carlos Fernández-Sánchez and Juan Garbajosa and Agustín Yagüe and Jennifer Perez},
keywords = {Technical debt, Technical debt management, Systematic mapping, Decision making, Basic decision-making factors, Cost estimation techniques, Practices and techniques for decision-making, Stakeholders’ points of view, Engineering, Engineering management, Business-organizational management, Framework},
abstract = {Technical debt, a metaphor for the long-term consequences of weak software development, must be managed to keep it under control. The main goal of this article is to identify and analyze the elements required to manage technical debt. The research method used to identify the elements is a systematic mapping, including a synthesis step to synthesize the elements definitions. Our perspective differs from previous literature reviews because it focused on the elements required to manage technical debt and not on the phenomenon of technical debt or the activities used in performing technical debt management. Additionally, the rigor and relevance for industry of the current techniques used to manage technical debt are studied. The elements were classified into three groups (basic decision-making factors, cost estimation techniques, practices and techniques for decision-making) and mapped according three stakeholders’ points of view (engineering, engineering management, and business-organizational management). The definitions, classification, and analysis of the elements provide a framework that can be deployed to help in the development of models that are adapted to the specific stakeholders’ interests to assist the decision-making required in technical debt management and to assess existing models and methods. The analysis indicated that technical debt management is context dependent.}
}
@article{BARISIC2022111081,
title = {Multi-paradigm modeling for cyber–physical systems: A systematic mapping review},
journal = {Journal of Systems and Software},
volume = {183},
pages = {111081},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111081},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221001783},
author = {Ankica Barišić and Ivan Ruchkin and Dušan Savić and Mustafa Abshir Mohamed and Rima Al-Ali and Letitia W. Li and Hana Mkaouar and Raheleh Eslampanah and Moharram Challenger and Dominique Blouin and Oksana Nikiforova and Antonio Cicchetti},
keywords = {Cyber–Physical System, Model, Formalism, Development process, Modeling paradigm, Systematic review},
abstract = {Cyber–Physical Systems (CPS) are heterogeneous and require cross-domain expertise to model. The complexity of these systems leads to questions about prevalent modeling approaches, their ability to integrate heterogeneous models, and their relevance to the application domains and stakeholders. The methodology for Multi-Paradigm Modeling (MPM) of CPS is not yet fully established and standardized, and researchers apply existing methods for modeling of complex systems and introducing their own. No systematic review has been previously performed to create an overview of the field on the methods used for MPM of CPS. In this paper, we present a systematic mapping study that determines the models, formalisms, and development processes used over the last decade. Additionally, to determine the knowledge necessary for developing CPS, our review studied the background of actors involved in modeling and authors of surveyed studies. The results of the survey show a tendency to reuse multiple existing formalisms and their associated paradigms, in addition to a tendency towards applying transformations between models. These findings suggest that MPM is becoming a essential approach to model CPS, and highlight the importance of future integration of models, standardization of development process and education.}
}
@article{TOM20131498,
title = {An exploration of technical debt},
journal = {Journal of Systems and Software},
volume = {86},
number = {6},
pages = {1498-1516},
year = {2013},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2012.12.052},
url = {https://www.sciencedirect.com/science/article/pii/S0164121213000022},
author = {Edith Tom and Aybüke Aurum and Richard Vidgen},
keywords = {Technical debt, Code debt, Precedents, Outcomes, Benefits and drawbacks, Multivocal literature review},
abstract = {Context
Whilst technical debt is considered to be detrimental to the long term success of software development, it appears to be poorly understood in academic literature. The absence of a clear definition and model for technical debt exacerbates the challenge of its identification and adequate management, thus preventing the realisation of technical debt's utility as a conceptual and technical communication device.
Objective
To make a critical examination of technical debt and consolidate understanding of the nature of technical debt and its implications for software development.
Method
An exploratory case study technique that involves multivocal literature review, supplemented by interviews with software practitioners and academics to establish the boundaries of the technical debt phenomenon.
Result
A key outcome of this research is the creation of a theoretical framework that provides a holistic view of technical debt comprising a set of technical debts dimensions, attributes, precedents and outcomes, as well as the phenomenon itself and a taxonomy that describes and encompasses different forms of the technical debt phenomenon.
Conclusion
The proposed framework provides a useful approach to understanding the overall phenomenon of technical debt for practical purposes. Future research should incorporate empirical studies to validate heuristics and techniques that will assist practitioners in their management of technical debt.}
}
@article{MANIKAS201684,
title = {Revisiting software ecosystems Research: A longitudinal literature study},
journal = {Journal of Systems and Software},
volume = {117},
pages = {84-103},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216000406},
author = {Konstantinos Manikas},
keywords = {Software ecosystems, Longitudinal literature study, Software ecosystem maturity},
abstract = {‘Software ecosystems’ is argued to first appear as a concept more than 10 years ago and software ecosystem research started to take off in 2010. We conduct a systematic literature study, based on the most extensive literature review in the field up to date, with two primarily aims: (a) to provide an updated overview of the field and (b) to document evolution in the field. In total, we analyze 231 papers from 2007 until 2014 and provide an overview of the research in software ecosystems. Our analysis reveals a field that is rapidly growing, both in volume and empirical focus, while becoming more mature. We identify signs of field maturity from the increase in: (i) the number of journal articles, (ii) the empirical models within the last two years, and (iii) the number of ecosystems studied. However, we note that the field is far from mature and identify a set of challenges that are preventing the field from evolving. We propose means for future research and the community to address them. Finally, our analysis shapes the view of the field having evolved outside the existing definitions of software ecosystems and thus propose the update of the definition of software ecosystems.}
}
@article{PITANGUEIRA2015267,
title = {Software requirements selection and prioritization using SBSE approaches: A systematic review and mapping of the literature},
journal = {Journal of Systems and Software},
volume = {103},
pages = {267-280},
year = {2015},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2014.09.038},
url = {https://www.sciencedirect.com/science/article/pii/S0164121214002118},
author = {Antônio Mauricio Pitangueira and Rita Suzana P. Maciel and Márcio Barros},
keywords = {Requirements selection, Requirements prioritization, Systematic review},
abstract = {The selection and prioritization of software requirements represents an area of interest in Search-Based Software Engineering (SBSE) and its main focus is finding and selecting a set of requirements that may be part of a software release. This paper presents a systematic review and mapping that investigated, analyzed, categorized and classified the SBSE approaches that have been proposed to address software requirement selection and prioritization problems, reporting quantitative and qualitative assessment. Initially 39 papers returned from our search strategy in this area and they were analyzed by 18 previously established quality criteria. The results of this systematic review show which aspects of the requirements selection and prioritization problems were addressed by researchers, which approaches and search techniques are currently adopted to address these problems, as well as the strengths and weaknesses in this research area highlighted from the quality criteria.}
}
@article{KARRAS2020110479,
title = {Representing software project vision by means of video: A quality model for vision videos},
journal = {Journal of Systems and Software},
volume = {162},
pages = {110479},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.110479},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219302535},
author = {Oliver Karras and Kurt Schneider and Samuel A. Fricker},
keywords = {Vision, Video, Vision video, Production, Quality characteristic, Quality model},
abstract = {Establishing a shared software project vision is a key challenge in Requirements Engineering (RE). Several approaches use videos to represent visions. However, these approaches omit how to produce a good video. This missing guidance is one crucial reason why videos are not established in RE. We propose a quality model for videos representing a vision, so-called vision videos. Based on two literature reviews, we elaborate ten quality characteristics of videos and five quality characteristics of visions which together form a quality model for vision videos that includes all 15 quality characteristics. We provide two representations of the quality model: (a) a hierarchical decomposition of vision video quality into the quality characteristics and (b) a mapping of these characteristics to the video production and use process. While the hierarchical decomposition supports the evaluation of vision videos, the mapping provides guidance for video production. In an evaluation with 139 students, we investigated whether the 15 characteristics are related to the overall quality of vision videos perceived by the subjects from a developer’s the point of view. Six characteristics (video length, focus, prior knowledge, clarity, pleasure, and stability) correlated significantly with the likelihood that the subjects perceived a vision video as good. These relationships substantiate a fundamental relevance of the proposed quality model. Therefore, we conclude that the quality model is a sound basis for future refinements and extensions.}
}
@article{PONCE2022111393,
title = {Smells and refactorings for microservices security: A multivocal literature review},
journal = {Journal of Systems and Software},
volume = {192},
pages = {111393},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111393},
url = {https://www.sciencedirect.com/science/article/pii/S016412122200111X},
author = {Francisco Ponce and Jacopo Soldani and Hernán Astudillo and Antonio Brogi},
abstract = {Context:
Securing microservices is crucial, as many IT companies are delivering their businesses through microservices. If security “smells” affect microservice-based applications, they can possibly suffer from security leaks and need to be refactored to mitigate the effects of security smells therein.
Objective:
As the available knowledge on securing microservices is scattered across different pieces of white and grey literature, our objective here is to distill well-known smells for securing microservices, together with the refactorings enabling to mitigate their effects.
Method:
To capture the state of the art and practice in securing microservices, we conducted a multivocal review of the existing white and grey literature on the topic. We systematically analysed 58 primary studies, selected among those published from 2011 until the end of 2020.
Results:
Ten bad smells for securing microservices are identified, which we organized in a taxonomy, associating each smell with the security properties it may violate and the refactorings enabling to mitigate its effects.
Conclusions:
The security smells and the corresponding refactorings have pragmatic value for practitioners, who can exploit them in their daily work on securing microservices. They also serve as a starting point for researchers wishing to establish new research directions on securing microservices.}
}
@article{PERNSTAL20132797,
title = {The lean gap: A review of lean approaches to large-scale software systems development},
journal = {Journal of Systems and Software},
volume = {86},
number = {11},
pages = {2797-2821},
year = {2013},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2013.06.035},
url = {https://www.sciencedirect.com/science/article/pii/S0164121213001477},
author = {J. Pernstål and R. Feldt and T. Gorschek},
keywords = {Systematic mapping study, Software engineering, Lean product development, Lean software development, Agile software development, Automotive software development},
abstract = {Lean approaches to product development (LPD) have had a strong influence on many industries and in recent years there have been many proponents for lean in software development as it can support the increasing industry need of scaling agile software development. With it's roots in industrial manufacturing and, later, industrial product development, it would seem natural that LPD would adapt well to large-scale development projects of increasingly software-intensive products, such as in the automotive industry. However, it is not clear what kind of experience and results have been reported on the actual use of lean principles and practices in software development for such large-scale industrial contexts. This was the motivation for this study as the context was an ongoing industry process improvement project at Volvo Car Corporation and Volvo Truck Corporation. The objectives of this study are to identify and classify state of the art in large-scale software development influenced by LPD approaches and use this established knowledge to support industrial partners in decisions on a software process improvement (SPI) project, and to reveal research gaps and proposed extensions to LPD in relation to its well-known principles and practices. For locating relevant state of the art we conducted a systematic mapping study, and the industrial applicability and relevance of results and said extensions to LPD were further analyzed in the context of an actual, industrial case. A total of 10,230 papers were found in database searches, of which 38 papers were found relevant. Of these, only 42 percent clearly addressed large-scale development. Furthermore, a majority of papers (76 percent) were non-empirical and many lacked information about study design, context and/or limitations. Most of the identified results focused on eliminating waste and creating flow in the software development process, but there was a lack of results for other LPD principles and practices. Overall, it can be concluded that research in the much hyped field of lean software development is in its nascent state when it comes to large scale development. There is very little support available for practitioners who want to apply lean approaches for improving large-scale software development, especially when it comes to inter-departmental interactions during development. This paper explicitly maps the area, qualifies available research, and identifies gaps, as well as suggests extensions to lean principles relevant for large scale development of software intensive systems.}
}
@article{KHABOU2017113,
title = {A novel analysis approach for the design and the development of context-aware applications},
journal = {Journal of Systems and Software},
volume = {133},
pages = {113-125},
year = {2017},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2017.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0164121217301528},
author = {Nesrine Khabou and Ismael {Bouassida Rodriguez} and Mohamed Jmaiel},
keywords = {Context-aware applications, Analysis procedure for detection, Analysis procedure for prediction, Adaptive thresholds, Prediction models, Extreme Value Theory},
abstract = {In this paper, we propose a novel analysis approach, called ANALOG, for the design and the development of context-aware applications able to detect context change and to predict context parameter values. Our approach is described by two analysis procedures, (a) an analysis procedure for detection and (b) an analysis procedure for prediction. The proposed analysis procedures aim to offer a support for application designers allowing them to design easily context-aware applications. Each procedure is achieved by a sequence of steps performed by the designers. We describe first our analysis approach presented by the analysis procedures. Then, we give some implementation details of our approach. Afterwards, we show the usefulness of the analysis approach through presenting two execution scenarios related to a smart building case study. Finally, to illustrate the effectiveness of our approach, we present different experiments related to (i) the processing time of the analysis approach and (ii) the CPU and the memory overhead introduced by our approach.}
}